{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed3aaa2",
   "metadata": {},
   "source": [
    "# Log Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc9fe2",
   "metadata": {},
   "source": [
    "In this document, we investigate log regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ab23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import f_classif\n",
    "import itertools\n",
    "import sys\n",
    "import importlib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "# from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, make_scorer\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from threadpoolctl import threadpool_limits\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import norm, t\n",
    "import warnings\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training\n",
    "importlib.reload(training);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410ef01",
   "metadata": {},
   "source": [
    "## Data importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f2ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/raw.csv\")\n",
    "features=list(df.columns)[1:]\n",
    "target=[\"Y\"]\n",
    "feat=df[features]\n",
    "tar=df[target]\n",
    "# x_t, x_v, y_t, y_v= train_test_split(feat,tar, test_size=0.2, random_state=0, stratify=tar[\"Y\"])\n",
    "n_splits=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ceeae",
   "metadata": {},
   "source": [
    "## For all raw features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057401c",
   "metadata": {},
   "source": [
    "Again, we use anova f test to determine a list of features that we will use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc565da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'X6', 'mean', 'F_w_mean', 'above_4', 'above_5'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe=Pipeline([(\"DataCreater\", training.data_creator()),(\"DataSelector\",training.data_selector())])\n",
    "tar_arr=np.ravel(tar.values)\n",
    "eva_pipe.fit(X=feat,y=tar)\n",
    "eva_out=eva_pipe.transform(X=feat)\n",
    "eva_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ce2d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>mean</th>\n",
       "      <th>F_w_mean</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.306094</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.235885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F_w_mean</td>\n",
       "      <td>12.615311</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.303878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features    f score   p value  ...   above_4   above_5         Y\n",
       "0         X1  10.561708  0.001486  ...  0.492355  0.604855  0.280160\n",
       "2         X3   2.886959  0.091807  ...  0.638649  0.481689  0.150838\n",
       "4         X5   6.582716  0.011488  ...  0.616787  0.586695  0.224522\n",
       "5         X6   3.586849  0.060568  ...  0.458477  0.490605  0.167669\n",
       "6       mean   7.306094  0.007836  ...  0.848710  0.773920  0.235885\n",
       "7   F_w_mean  12.615311  0.000542  ...  0.743851  0.761327  0.303878\n",
       "9    above_4   7.194813  0.008308  ...  1.000000  0.546995  0.234181\n",
       "10   above_5   6.520675  0.011874  ...  0.546995  1.000000  0.223515\n",
       "\n",
       "[8 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe[\"DataSelector\"].sel_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3efac2",
   "metadata": {},
   "source": [
    "The penalties should be able to replace exhaust feature subset search for removing high colinearity. But it does not heart to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd6cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1020 out of 1020 | elapsed:  8.3min finished\n"
     ]
    }
   ],
   "source": [
    "penalty_choice=[\"l1\",\"l2\",\"elasticnet\", None]\n",
    "range_feat_combin = training.all_combin(eva_out.columns)\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, penalty, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination. \n",
    "    :param penalty: The penalty of logregression used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "        \n",
    "    \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"DataCreate\", training.data_creator()),\n",
    "                (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "                (\"scale\", StandardScaler()),\n",
    "                (\"LogReg\", LogisticRegression(penalty=penalty,solver=\"saga\", l1_ratio=0.1)),\n",
    "            ])\n",
    "            \n",
    "            pipe.fit(X=x_tr, y=y_tr)\n",
    "            y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and penalty {penalty}.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"features\": str_features,\n",
    "        \"penalty\": penalty,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, penalty_choice))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, penalty, splits, feat, tar)\n",
    "    for feat_sel, penalty in jobs\n",
    ")\n",
    "\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_penalty        = [r[\"penalty\"] for r in results]\n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "999585f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"penalty\": list_penalty,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7267e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>penalty</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.635523</td>\n",
       "      <td>0.077083</td>\n",
       "      <td>0.663823</td>\n",
       "      <td>0.081786</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.110166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X1</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.632354</td>\n",
       "      <td>0.073982</td>\n",
       "      <td>0.664249</td>\n",
       "      <td>0.081117</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.632354</td>\n",
       "      <td>0.073982</td>\n",
       "      <td>0.664249</td>\n",
       "      <td>0.081117</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>above_4</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.610508</td>\n",
       "      <td>0.083655</td>\n",
       "      <td>0.680617</td>\n",
       "      <td>0.106366</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>X3,X5,above_4,above_5</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.556523</td>\n",
       "      <td>0.086685</td>\n",
       "      <td>0.616065</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>X1,X3,X5,X6,mean,F_w_mean,above_5</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.543662</td>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.609816</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>X1,X3,X5,X6,mean,F_w_mean,above_5</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.545631</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.611738</td>\n",
       "      <td>0.071695</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.552369</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>0.675819</td>\n",
       "      <td>0.058102</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.550785</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.675156</td>\n",
       "      <td>0.057392</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X3</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.551185</td>\n",
       "      <td>0.071972</td>\n",
       "      <td>0.675374</td>\n",
       "      <td>0.057690</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features  ... acc_mean_above_73\n",
       "3                                   X1  ...               0.0\n",
       "2                                   X1  ...               0.0\n",
       "1                                   X1  ...               0.0\n",
       "26                             above_4  ...               0.0\n",
       "546              X3,X5,above_4,above_5  ...               0.0\n",
       "..                                 ...  ...               ...\n",
       "990  X1,X3,X5,X6,mean,F_w_mean,above_5  ...               0.0\n",
       "989  X1,X3,X5,X6,mean,F_w_mean,above_5  ...               0.0\n",
       "7                                   X3  ...               0.0\n",
       "6                                   X3  ...               0.0\n",
       "5                                   X3  ...               0.0\n",
       "\n",
       "[1020 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by=[\"above_73\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e117bc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>penalty</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X6</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.605154</td>\n",
       "      <td>0.066580</td>\n",
       "      <td>0.709280</td>\n",
       "      <td>0.065599</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X6</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.603954</td>\n",
       "      <td>0.067969</td>\n",
       "      <td>0.705747</td>\n",
       "      <td>0.072236</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X6</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.603954</td>\n",
       "      <td>0.067969</td>\n",
       "      <td>0.705747</td>\n",
       "      <td>0.072236</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X6</td>\n",
       "      <td>None</td>\n",
       "      <td>0.605569</td>\n",
       "      <td>0.071387</td>\n",
       "      <td>0.704744</td>\n",
       "      <td>0.078659</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>above_4</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.617708</td>\n",
       "      <td>0.079668</td>\n",
       "      <td>0.690989</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.079343</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>X6,mean,above_5</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.526462</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>0.576594</td>\n",
       "      <td>0.097760</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>X3,X6,mean,above_5</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.523262</td>\n",
       "      <td>0.086536</td>\n",
       "      <td>0.573786</td>\n",
       "      <td>0.094723</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>X6,mean,above_5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.522508</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.573583</td>\n",
       "      <td>0.095267</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>X3,X6,mean,above_5</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.522062</td>\n",
       "      <td>0.086666</td>\n",
       "      <td>0.573154</td>\n",
       "      <td>0.094703</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>X3,X6,mean,above_5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520077</td>\n",
       "      <td>0.084027</td>\n",
       "      <td>0.569672</td>\n",
       "      <td>0.093612</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               features     penalty  ...  norm_above_73  acc_mean_above_73\n",
       "12                   X6          l1  ...       0.030387                0.0\n",
       "14                   X6  elasticnet  ...       0.031837                0.0\n",
       "13                   X6          l2  ...       0.031837                0.0\n",
       "15                   X6        None  ...       0.040663                0.0\n",
       "24              above_4          l1  ...       0.079343                0.0\n",
       "..                  ...         ...  ...            ...                ...\n",
       "337     X6,mean,above_5          l2  ...       0.011067                0.0\n",
       "557  X3,X6,mean,above_5          l2  ...       0.008446                0.0\n",
       "339     X6,mean,above_5        None  ...       0.007958                0.0\n",
       "558  X3,X6,mean,above_5  elasticnet  ...       0.008213                0.0\n",
       "559  X3,X6,mean,above_5        None  ...       0.006240                0.0\n",
       "\n",
       "[1020 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by=[\"f1_mean\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05d0c2",
   "metadata": {},
   "source": [
    "I would still prefer to consider 3 as the best model. It only used X1 and no penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d3dd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"../data/LogReg_results_exhaust_raw6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757e9a0",
   "metadata": {},
   "source": [
    "Log Regression is not really performing here, and is not really giving me anything too interesting: It is literally saying we are better off just stare at X1 only. I do not think further investigation will be interesting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
