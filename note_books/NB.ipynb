{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324c3505",
   "metadata": {},
   "source": [
    "# Naive Bayesian methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957014da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import f_classif\n",
    "import itertools\n",
    "import sys\n",
    "import importlib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OrdinalEncoder\n",
    "# from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, make_scorer\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from threadpoolctl import threadpool_limits\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import norm, t\n",
    "from sklearn.base import clone \n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training\n",
    "importlib.reload(training);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2f6d4",
   "metadata": {},
   "source": [
    "## Data importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9027140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/raw.csv\")\n",
    "features=list(df.columns)[1:]\n",
    "target=[\"Y\"]\n",
    "feat=df[features]\n",
    "tar=df[target]\n",
    "# x_t, x_v, y_t, y_v= train_test_split(feat,tar, test_size=0.2, random_state=0, stratify=tar[\"Y\"])\n",
    "n_splits=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0148b",
   "metadata": {},
   "source": [
    "## For all raw features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a52551b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'X6', 'mean', 'F_w_mean', 'above_4', 'above_5',\n",
       "       'count_3', 'count_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe=Pipeline([(\"DataCreater\", training.data_creator(counts=True)),(\"DataSelector\",training.data_selector())])\n",
    "tar_arr=np.ravel(tar.values)\n",
    "eva_pipe.fit(X=feat,y=tar)\n",
    "eva_out=eva_pipe.transform(X=feat)\n",
    "eva_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75b56888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>mean</th>\n",
       "      <th>F_w_mean</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.306094</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.235885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F_w_mean</td>\n",
       "      <td>12.615311</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.303878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features    f score   p value        X1        X2        X3        X4  \\\n",
       "0         X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "2         X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "4         X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5         X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6       mean   7.306094  0.007836  0.607460  0.426097  0.676149  0.557803   \n",
       "7   F_w_mean  12.615311  0.000542  0.834641  0.078909  0.532371  0.298662   \n",
       "9    above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "10   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "13   count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "15   count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6      mean  F_w_mean   above_3   above_4   above_5  \\\n",
       "0   0.432772  0.411873  0.607460  0.834641  0.266199  0.492355  0.604855   \n",
       "2   0.358397  0.203750  0.676149  0.532371  0.442280  0.638649  0.481689   \n",
       "4   1.000000  0.320195  0.712786  0.806779  0.491804  0.616787  0.586695   \n",
       "5   0.320195  1.000000  0.540096  0.574523  0.261704  0.458477  0.490605   \n",
       "6   0.712786  0.540096  1.000000  0.869373  0.687659  0.848710  0.773920   \n",
       "7   0.806779  0.574523  0.869373  1.000000  0.498831  0.743851  0.761327   \n",
       "9   0.616787  0.458477  0.848710  0.743851  0.465645  1.000000  0.546995   \n",
       "10  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "13 -0.343809 -0.327806 -0.465487 -0.480216  0.177713 -0.788134 -0.448806   \n",
       "15  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "\n",
       "     count_1   count_2   count_3   count_4   count_5         Y  \n",
       "0  -0.272144 -0.063015 -0.362352 -0.182806  0.604855  0.280160  \n",
       "2  -0.368676 -0.189451 -0.402565  0.097357  0.481689  0.150838  \n",
       "4  -0.292405 -0.330012 -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.275081 -0.054304 -0.327806 -0.090021  0.490605  0.167669  \n",
       "6  -0.557112 -0.310913 -0.465487 -0.018374  0.773920  0.235885  \n",
       "7  -0.397480 -0.232290 -0.480216 -0.107788  0.761327  0.303878  \n",
       "9  -0.306616 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "10 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "13 -0.103910 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "15 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe[\"DataSelector\"].sel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f6c34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>mean</th>\n",
       "      <th>F_w_mean</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.306094</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.235885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F_w_mean</td>\n",
       "      <td>12.615311</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.303878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features    f score   p value        X1        X2        X3        X4  \\\n",
       "0         X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "1         X2   0.073108  0.787313  0.059797  1.000000  0.184129  0.114838   \n",
       "2         X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "3         X4   0.516657  0.473623  0.087541  0.114838  0.302618  1.000000   \n",
       "4         X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5         X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6       mean   7.306094  0.007836  0.607460  0.426097  0.676149  0.557803   \n",
       "7   F_w_mean  12.615311  0.000542  0.834641  0.078909  0.532371  0.298662   \n",
       "8    above_3   1.032794  0.311482  0.266199  0.500598  0.442280  0.383442   \n",
       "9    above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "10   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "11   count_1   0.457080  0.500251 -0.272144 -0.420657 -0.368676 -0.308409   \n",
       "12   count_2   0.366975  0.545765 -0.063015 -0.211012 -0.189451 -0.175639   \n",
       "13   count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "14   count_4   0.032071  0.858165 -0.182806  0.027148  0.097357  0.083189   \n",
       "15   count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6      mean  F_w_mean   above_3   above_4   above_5  \\\n",
       "0   0.432772  0.411873  0.607460  0.834641  0.266199  0.492355  0.604855   \n",
       "1   0.039996 -0.062205  0.426097  0.078909  0.500598  0.268810  0.215269   \n",
       "2   0.358397  0.203750  0.676149  0.532371  0.442280  0.638649  0.481689   \n",
       "3   0.293115  0.215888  0.557803  0.298662  0.383442  0.521454  0.389949   \n",
       "4   1.000000  0.320195  0.712786  0.806779  0.491804  0.616787  0.586695   \n",
       "5   0.320195  1.000000  0.540096  0.574523  0.261704  0.458477  0.490605   \n",
       "6   0.712786  0.540096  1.000000  0.869373  0.687659  0.848710  0.773920   \n",
       "7   0.806779  0.574523  0.869373  1.000000  0.498831  0.743851  0.761327   \n",
       "8   0.491804  0.261704  0.687659  0.498831  1.000000  0.465645  0.229256   \n",
       "9   0.616787  0.458477  0.848710  0.743851  0.465645  1.000000  0.546995   \n",
       "10  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "11 -0.292405 -0.275081 -0.557112 -0.397480 -0.639627 -0.306616 -0.129758   \n",
       "12 -0.330012 -0.054304 -0.310913 -0.232290 -0.625264 -0.282240 -0.160484   \n",
       "13 -0.343809 -0.327806 -0.465487 -0.480216  0.177713 -0.788134 -0.448806   \n",
       "14 -0.040143 -0.090021 -0.018374 -0.107788  0.205652  0.381294 -0.565327   \n",
       "15  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "\n",
       "     count_1   count_2   count_3   count_4   count_5         Y  \n",
       "0  -0.272144 -0.063015 -0.362352 -0.182806  0.604855  0.280160  \n",
       "1  -0.420657 -0.211012  0.049254  0.027148  0.215269 -0.024274  \n",
       "2  -0.368676 -0.189451 -0.402565  0.097357  0.481689  0.150838  \n",
       "3  -0.308409 -0.175639 -0.313167  0.083189  0.389949  0.064415  \n",
       "4  -0.292405 -0.330012 -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.275081 -0.054304 -0.327806 -0.090021  0.490605  0.167669  \n",
       "6  -0.557112 -0.310913 -0.465487 -0.018374  0.773920  0.235885  \n",
       "7  -0.397480 -0.232290 -0.480216 -0.107788  0.761327  0.303878  \n",
       "8  -0.639627 -0.625264  0.177713  0.205652  0.229256  0.090886  \n",
       "9  -0.306616 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "10 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "11  1.000000 -0.199957 -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "12 -0.199957  1.000000 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "13 -0.103910 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "14 -0.158830 -0.100881 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "15 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe[\"DataSelector\"].total_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f2d70",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c2f2e",
   "metadata": {},
   "source": [
    "Gaussian takes any value, so we will just send everything we believe will be helpful in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b76fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1023 out of 1023 | elapsed: 16.7min finished\n"
     ]
    }
   ],
   "source": [
    "range_feat_combin = training.all_combin(eva_out.columns)\n",
    "model_choice={\n",
    "    \"Gaussian\": GaussianNB()\n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"NB\", clone(model_choice[model_name])),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3efb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Gus = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9dd11d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>X3,X5,mean,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.611031</td>\n",
       "      <td>0.082613</td>\n",
       "      <td>0.655625</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.074922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>X1,X5,above_5,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.608231</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.616037</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.070716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>X1,X5,F_w_mean,above_5,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.608292</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.621565</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>X3,X5,mean,F_w_mean,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.648501</td>\n",
       "      <td>0.086814</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>X3,X5,mean,above_4,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.607815</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.084667</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>X1,X3,X5,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.086067</td>\n",
       "      <td>0.556404</td>\n",
       "      <td>0.100495</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>X1,X3,X6,mean,F_w_mean,above_4,above_5,count_3...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.520923</td>\n",
       "      <td>0.080230</td>\n",
       "      <td>0.545198</td>\n",
       "      <td>0.094876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>X1,X5,X6,mean,F_w_mean,above_4,above_5,count_3...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.544385</td>\n",
       "      <td>0.085483</td>\n",
       "      <td>0.567705</td>\n",
       "      <td>0.099150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.587569</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.670835</td>\n",
       "      <td>0.076213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>X1,X3,X5,X6,mean,F_w_mean,above_4,above_5,coun...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.534369</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.557966</td>\n",
       "      <td>0.099476</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features     model  acc_mean  \\\n",
       "268                                  X3,X5,mean,count_3  Gaussian  0.611031   \n",
       "222                               X1,X5,above_5,count_5  Gaussian  0.608231   \n",
       "470                      X1,X5,F_w_mean,above_5,count_5  Gaussian  0.608292   \n",
       "528                         X3,X5,mean,F_w_mean,count_3  Gaussian  0.603846   \n",
       "531                          X3,X5,mean,above_4,count_3  Gaussian  0.607815   \n",
       "...                                                 ...       ...       ...   \n",
       "981         X1,X3,X5,X6,above_4,above_5,count_3,count_5  Gaussian  0.540785   \n",
       "1019  X1,X3,X6,mean,F_w_mean,above_4,above_5,count_3...  Gaussian  0.520923   \n",
       "1020  X1,X5,X6,mean,F_w_mean,above_4,above_5,count_3...  Gaussian  0.544385   \n",
       "2                                                    X5  Gaussian  0.587569   \n",
       "1022  X1,X3,X5,X6,mean,F_w_mean,above_4,above_5,coun...  Gaussian  0.534369   \n",
       "\n",
       "       acc_std   f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "268   0.082613  0.655625  0.083925      0.09       0.074922                0.0  \n",
       "222   0.082809  0.616037  0.100953      0.08       0.070716                0.0  \n",
       "470   0.081815  0.621565  0.097477      0.07       0.068429                0.0  \n",
       "528   0.083175  0.648501  0.086814      0.07       0.064668                0.0  \n",
       "531   0.081609  0.655354  0.084667      0.07       0.067172                0.0  \n",
       "...        ...       ...       ...       ...            ...                ...  \n",
       "981   0.086067  0.556404  0.100495      0.00       0.013958                0.0  \n",
       "1019  0.080230  0.545198  0.094876      0.00       0.004581                0.0  \n",
       "1020  0.085483  0.567705  0.099150      0.00       0.014951                0.0  \n",
       "2     0.070839  0.670835  0.076213      0.00       0.022183                0.0  \n",
       "1022  0.087555  0.557966  0.099476      0.00       0.012729                0.0  \n",
       "\n",
       "[1023 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Gus.sort_values(by=[\"above_73\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "082a0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Gus.to_csv(\"../data/NB_Gus_results_exhaust_raw6.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b813c",
   "metadata": {},
   "source": [
    "### Count intakes: Multinomial and Complement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a8734",
   "metadata": {},
   "source": [
    "Multinomial and complement methods takes counts and frequencies only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f401db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      above_3   above_4   above_5  count_1  count_2  count_3  count_4  count_5\n",
       "0    0.833333  0.333333  0.000000        0        1        3        2        0\n",
       "1    0.833333  0.333333  0.166667        0        1        3        1        1\n",
       "2    1.000000  0.333333  0.333333        0        0        4        0        2\n",
       "3    1.000000  0.500000  0.333333        0        0        3        1        2\n",
       "4    1.000000  0.500000  0.333333        0        0        3        1        2\n",
       "..        ...       ...       ...      ...      ...      ...      ...      ...\n",
       "121  0.833333  0.500000  0.166667        0        1        2        2        1\n",
       "122  0.666667  0.500000  0.333333        0        2        1        1        2\n",
       "123  1.000000  0.666667  0.333333        0        0        2        2        2\n",
       "124  1.000000  0.666667  0.166667        0        0        2        3        1\n",
       "125  0.833333  0.666667  0.666667        0        1        1        0        4\n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_feat=training.data_creator(counts=True)\n",
    "all_count_feat=[\"above_3\",\"above_4\",\"above_5\",\"count_1\", \"count_2\", \"count_3\", \"count_4\", \"count_5\"]\n",
    "eva_feat_out=eva_feat.fit(X=feat,y=tar).transform(X=feat)\n",
    "eva_feat_out=eva_feat_out[all_count_feat]\n",
    "eva_feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "376919b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['above_3', 'above_4', 'above_5', 'count_3', 'count_5'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel=training.data_selector(how=\"or\")\n",
    "eva_sel_out=eva_sel.fit(X=eva_feat_out,y=tar).transform(X=eva_feat_out)\n",
    "eva_sel_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8d13a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features   f score   p value   above_3   above_4   above_5   count_1  \\\n",
       "0  above_3  1.032794  0.311482  1.000000  0.465645  0.229256 -0.639627   \n",
       "1  above_4  7.194813  0.008308  0.465645  1.000000  0.546995 -0.306616   \n",
       "2  above_5  6.520675  0.011874  0.229256  0.546995  1.000000 -0.129758   \n",
       "3  count_1  0.457080  0.500251 -0.639627 -0.306616 -0.129758  1.000000   \n",
       "4  count_2  0.366975  0.545765 -0.625264 -0.282240 -0.160484 -0.199957   \n",
       "5  count_3  5.016985  0.026881  0.177713 -0.788134 -0.448806 -0.103910   \n",
       "6  count_4  0.032071  0.858165  0.205652  0.381294 -0.565327 -0.158830   \n",
       "7  count_5  6.520675  0.011874  0.229256  0.546995  1.000000 -0.129758   \n",
       "\n",
       "    count_2   count_3   count_4   count_5         Y  \n",
       "0 -0.625264  0.177713  0.205652  0.229256  0.090886  \n",
       "1 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "2 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "3 -0.199957 -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "4  1.000000 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "5 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "6 -0.100881 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "7 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5ac9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  62 | elapsed:   47.1s remaining:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  62 | elapsed:   47.9s remaining:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  62 | elapsed:   59.7s remaining:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  62 | elapsed:  1.0min remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "count_feats=list(eva_sel_out.columns)\n",
    "range_feat_combin = training.all_combin(count_feats)\n",
    "model_choice={\n",
    "    \"Multinomial\": MultinomialNB(),\n",
    "    \"Complement\": ComplementNB() \n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"NB\", clone(model_choice[model_name])),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6af97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Counters = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bec6d909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>above_3,above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.625169</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.807641e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>above_5,count_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.578092</td>\n",
       "      <td>0.095263</td>\n",
       "      <td>0.536779</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.540021e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>above_5,count_3,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.594431</td>\n",
       "      <td>0.090290</td>\n",
       "      <td>0.584287</td>\n",
       "      <td>0.136699</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.661418e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.619569</td>\n",
       "      <td>0.060633</td>\n",
       "      <td>0.712132</td>\n",
       "      <td>0.048961</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.428163e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>count_3,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.136625</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.465733e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>above_3,above_4,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.548169</td>\n",
       "      <td>0.074767</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.508512e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>above_4,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.548062</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.703915</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.527702e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>above_3,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.549338</td>\n",
       "      <td>0.070298</td>\n",
       "      <td>0.649575</td>\n",
       "      <td>0.067834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.085565e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>above_3,above_4,above_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.707611</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>above_3,above_4,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.074828</td>\n",
       "      <td>0.643519</td>\n",
       "      <td>0.072263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.134050e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           features        model  acc_mean   acc_std  \\\n",
       "32          above_3,above_4,count_3  Multinomial  0.625169  0.063007   \n",
       "25                  above_5,count_3   Complement  0.578092  0.095263   \n",
       "49          above_5,count_3,count_5   Complement  0.594431  0.090290   \n",
       "20                  above_4,count_3  Multinomial  0.619569  0.060633   \n",
       "29                  count_3,count_5   Complement  0.594031  0.089642   \n",
       "..                              ...          ...       ...       ...   \n",
       "34          above_3,above_4,count_5  Multinomial  0.548169  0.074767   \n",
       "44          above_4,above_5,count_5  Multinomial  0.548062  0.033387   \n",
       "38          above_3,above_5,count_5  Multinomial  0.549338  0.070298   \n",
       "30          above_3,above_4,above_5  Multinomial  0.547692  0.016165   \n",
       "52  above_3,above_4,above_5,count_5  Multinomial  0.550200  0.074828   \n",
       "\n",
       "     f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "32  0.710032  0.052744      0.08   4.807641e-02                0.0  \n",
       "25  0.536779  0.146137      0.07   5.540021e-02                0.0  \n",
       "49  0.584287  0.136699      0.07   6.661418e-02                0.0  \n",
       "20  0.712132  0.048961      0.06   3.428163e-02                0.0  \n",
       "29  0.584214  0.136625      0.06   6.465733e-02                0.0  \n",
       "..       ...       ...       ...            ...                ...  \n",
       "34  0.645688  0.072604      0.00   7.508512e-03                0.0  \n",
       "44  0.703915  0.026137      0.00   2.527702e-08                0.0  \n",
       "38  0.649575  0.067834      0.00   5.085565e-03                0.0  \n",
       "30  0.707611  0.013610      0.00   0.000000e+00                0.0  \n",
       "52  0.643519  0.072263      0.00   8.134050e-03                0.0  \n",
       "\n",
       "[62 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Counters.sort_values(by=[\"above_73\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b59631a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>above_3,above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.625169</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.619569</td>\n",
       "      <td>0.060633</td>\n",
       "      <td>0.712132</td>\n",
       "      <td>0.048961</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>above_3,above_5,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.609169</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.687830</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>above_4,above_5,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.598077</td>\n",
       "      <td>0.084128</td>\n",
       "      <td>0.665227</td>\n",
       "      <td>0.088955</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>above_5,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.595215</td>\n",
       "      <td>0.081296</td>\n",
       "      <td>0.660414</td>\n",
       "      <td>0.073376</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.048663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>above_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above_4</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>above_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features        model  acc_mean   acc_std   f1_mean  \\\n",
       "32  above_3,above_4,count_3  Multinomial  0.625169  0.063007  0.710032   \n",
       "20          above_4,count_3  Multinomial  0.619569  0.060633  0.712132   \n",
       "36  above_3,above_5,count_3  Multinomial  0.609169  0.073740  0.687830   \n",
       "42  above_4,above_5,count_3  Multinomial  0.598077  0.084128  0.665227   \n",
       "27          above_5,count_5   Complement  0.595215  0.081296  0.660414   \n",
       "..                      ...          ...       ...       ...       ...   \n",
       "5                   above_5   Complement  0.452308  0.016165  0.000000   \n",
       "7                   count_3   Complement  0.452308  0.016165  0.000000   \n",
       "3                   above_4   Complement  0.452308  0.016165  0.000000   \n",
       "9                   count_5   Complement  0.452308  0.016165  0.000000   \n",
       "1                   above_3   Complement  0.452308  0.016165  0.000000   \n",
       "\n",
       "      f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "32  0.052744      0.08       0.048076                0.0  \n",
       "20  0.048961      0.06       0.034282                0.0  \n",
       "36  0.070713      0.04       0.050648                0.0  \n",
       "42  0.088955      0.05       0.058425                0.0  \n",
       "27  0.073376      0.03       0.048663                0.0  \n",
       "..       ...       ...            ...                ...  \n",
       "5   0.000000      0.00       0.000000                0.0  \n",
       "7   0.000000      0.00       0.000000                0.0  \n",
       "3   0.000000      0.00       0.000000                0.0  \n",
       "9   0.000000      0.00       0.000000                0.0  \n",
       "1   0.000000      0.00       0.000000                0.0  \n",
       "\n",
       "[62 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Counters.sort_values(by=[\"acc_mean\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93561d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Counters.to_csv(\"../data/NB_Counter_exhaust_raw6.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e9877",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718119",
   "metadata": {},
   "source": [
    "We will remove the features that are not categorical (or simply has too many categories). And we will add a OrdinalEncoder layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91bf82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1  X2  X3  X4  X5  X6   above_3   above_4   above_5  count_1  count_2  \\\n",
       "0     3   3   3   4   2   4  0.833333  0.333333  0.000000        0        1   \n",
       "1     3   2   3   5   4   3  0.833333  0.333333  0.166667        0        1   \n",
       "2     5   3   3   3   3   5  1.000000  0.333333  0.333333        0        0   \n",
       "3     5   4   3   3   3   5  1.000000  0.500000  0.333333        0        0   \n",
       "4     5   4   3   3   3   5  1.000000  0.500000  0.333333        0        0   \n",
       "..   ..  ..  ..  ..  ..  ..       ...       ...       ...      ...      ...   \n",
       "121   5   2   3   4   4   3  0.833333  0.500000  0.166667        0        1   \n",
       "122   5   2   3   4   2   5  0.666667  0.500000  0.333333        0        2   \n",
       "123   5   3   3   4   4   5  1.000000  0.666667  0.333333        0        0   \n",
       "124   4   3   3   4   4   5  1.000000  0.666667  0.166667        0        0   \n",
       "125   5   3   2   5   5   5  0.833333  0.666667  0.666667        0        1   \n",
       "\n",
       "     count_3  count_4  count_5  \n",
       "0          3        2        0  \n",
       "1          3        1        1  \n",
       "2          4        0        2  \n",
       "3          3        1        2  \n",
       "4          3        1        2  \n",
       "..       ...      ...      ...  \n",
       "121        2        2        1  \n",
       "122        1        1        2  \n",
       "123        2        2        2  \n",
       "124        2        3        1  \n",
       "125        1        0        4  \n",
       "\n",
       "[126 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_feat=training.data_creator(counts=True)\n",
    "eva_feat_out=eva_feat.fit(X=feat,y=tar).transform(X=feat)\n",
    "all_cat_feat=[feature for feature in eva_feat_out.columns if feature not in [\"F_w_mean\",\"mean\"]] \n",
    "eva_feat_out=eva_feat_out[all_cat_feat]\n",
    "eva_feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61c0d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [np.int64(1), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X2': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X3': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X4': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X5': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X6': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'above_3': [np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'above_4': [np.float64(0.0),\n",
       "  np.float64(0.16666666666666666),\n",
       "  np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'above_5': [np.float64(0.0),\n",
       "  np.float64(0.16666666666666666),\n",
       "  np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'count_1': [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)],\n",
       " 'count_2': [np.int64(0), np.int64(1), np.int64(2), np.int64(3)],\n",
       " 'count_3': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)],\n",
       " 'count_4': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)],\n",
       " 'count_5': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5),\n",
       "  np.int64(6)]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat=dict()\n",
    "for key in eva_feat_out.columns: \n",
    "    dict_cat[key]=sorted(list(eva_feat_out[key].unique()))\n",
    "dict_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7837366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'X6', 'above_4', 'above_5', 'count_3', 'count_5'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel=training.data_selector()\n",
    "eva_sel_out=eva_sel.fit(X=eva_feat_out,y=tar).transform(X=eva_feat_out)\n",
    "eva_sel_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3fff798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features    f score   p value        X1        X2        X3        X4  \\\n",
       "0        X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "1        X2   0.073108  0.787313  0.059797  1.000000  0.184129  0.114838   \n",
       "2        X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "3        X4   0.516657  0.473623  0.087541  0.114838  0.302618  1.000000   \n",
       "4        X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5        X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6   above_3   1.032794  0.311482  0.266199  0.500598  0.442280  0.383442   \n",
       "7   above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "8   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "9   count_1   0.457080  0.500251 -0.272144 -0.420657 -0.368676 -0.308409   \n",
       "10  count_2   0.366975  0.545765 -0.063015 -0.211012 -0.189451 -0.175639   \n",
       "11  count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "12  count_4   0.032071  0.858165 -0.182806  0.027148  0.097357  0.083189   \n",
       "13  count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6   above_3   above_4   above_5   count_1   count_2  \\\n",
       "0   0.432772  0.411873  0.266199  0.492355  0.604855 -0.272144 -0.063015   \n",
       "1   0.039996 -0.062205  0.500598  0.268810  0.215269 -0.420657 -0.211012   \n",
       "2   0.358397  0.203750  0.442280  0.638649  0.481689 -0.368676 -0.189451   \n",
       "3   0.293115  0.215888  0.383442  0.521454  0.389949 -0.308409 -0.175639   \n",
       "4   1.000000  0.320195  0.491804  0.616787  0.586695 -0.292405 -0.330012   \n",
       "5   0.320195  1.000000  0.261704  0.458477  0.490605 -0.275081 -0.054304   \n",
       "6   0.491804  0.261704  1.000000  0.465645  0.229256 -0.639627 -0.625264   \n",
       "7   0.616787  0.458477  0.465645  1.000000  0.546995 -0.306616 -0.282240   \n",
       "8   0.586695  0.490605  0.229256  0.546995  1.000000 -0.129758 -0.160484   \n",
       "9  -0.292405 -0.275081 -0.639627 -0.306616 -0.129758  1.000000 -0.199957   \n",
       "10 -0.330012 -0.054304 -0.625264 -0.282240 -0.160484 -0.199957  1.000000   \n",
       "11 -0.343809 -0.327806  0.177713 -0.788134 -0.448806 -0.103910 -0.121027   \n",
       "12 -0.040143 -0.090021  0.205652  0.381294 -0.565327 -0.158830 -0.100881   \n",
       "13  0.586695  0.490605  0.229256  0.546995  1.000000 -0.129758 -0.160484   \n",
       "\n",
       "     count_3   count_4   count_5         Y  \n",
       "0  -0.362352 -0.182806  0.604855  0.280160  \n",
       "1   0.049254  0.027148  0.215269 -0.024274  \n",
       "2  -0.402565  0.097357  0.481689  0.150838  \n",
       "3  -0.313167  0.083189  0.389949  0.064415  \n",
       "4  -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.327806 -0.090021  0.490605  0.167669  \n",
       "6   0.177713  0.205652  0.229256  0.090886  \n",
       "7  -0.788134  0.381294  0.546995  0.234181  \n",
       "8  -0.448806 -0.565327  1.000000  0.223515  \n",
       "9  -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "10 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "11  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "12 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "13 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c18ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 255 | elapsed:  4.2min remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 255 out of 255 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "count_feats=list(eva_sel_out.columns)\n",
    "range_feat_combin = training.all_combin(count_feats)\n",
    "model_choice={\n",
    "    \"Categorical\": None\n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "        \n",
    "        cats=[dict_cat[key] for key in list_f_sel]\n",
    "        \n",
    "        K=max(len(c) for c in cats)\n",
    "        \n",
    "        min_cats=[max(len(c), K + 1) for c in cats]\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"OrEncoder\", OrdinalEncoder(categories=cats,handle_unknown=\"use_encoded_value\",unknown_value=K,dtype=int)), \n",
    "            (\"NB\", CategoricalNB(min_categories=min_cats)),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9ac2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac1537f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X1,X6,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.661431</td>\n",
       "      <td>0.092942</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>0.094698</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.230330</td>\n",
       "      <td>8.060219e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X1,X6,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.640415</td>\n",
       "      <td>0.089925</td>\n",
       "      <td>0.689160</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.638292</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.148064</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>X1,X6,above_4,above_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.665343</td>\n",
       "      <td>0.091472</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>X1,X6,above_4,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.665343</td>\n",
       "      <td>0.091472</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>X3,X5,above_4,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.076875</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>X3,X5,above_4,above_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.076875</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>X5,X6,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.084510</td>\n",
       "      <td>0.590776</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>X1,X3,X5,above_4,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.584846</td>\n",
       "      <td>0.070933</td>\n",
       "      <td>0.626930</td>\n",
       "      <td>0.074792</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>X1,X3,X5,above_4,above_5,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.584846</td>\n",
       "      <td>0.070933</td>\n",
       "      <td>0.626930</td>\n",
       "      <td>0.074792</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features        model  acc_mean   acc_std  \\\n",
       "47                      X1,X6,above_4  Categorical  0.661431  0.092942   \n",
       "118             X1,X6,above_4,count_3  Categorical  0.640415  0.089925   \n",
       "0                                  X1  Categorical  0.638292  0.087778   \n",
       "117             X1,X6,above_4,above_5  Categorical  0.634769  0.087533   \n",
       "119             X1,X6,above_4,count_5  Categorical  0.634769  0.087533   \n",
       "..                                ...          ...       ...       ...   \n",
       "133             X3,X5,above_4,count_5  Categorical  0.578908  0.076875   \n",
       "131             X3,X5,above_4,above_5  Categorical  0.578908  0.076875   \n",
       "215     X5,X6,above_5,count_3,count_5  Categorical  0.564246  0.084510   \n",
       "226  X1,X3,X5,above_4,count_3,count_5  Categorical  0.584846  0.070933   \n",
       "224  X1,X3,X5,above_4,above_5,count_3  Categorical  0.584846  0.070933   \n",
       "\n",
       "      f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "47   0.704892  0.094698      0.24       0.230330       8.060219e-14  \n",
       "118  0.689160  0.085676      0.16       0.159574       0.000000e+00  \n",
       "0    0.661949  0.088259      0.15       0.148064       0.000000e+00  \n",
       "117  0.665343  0.091472      0.11       0.138311       0.000000e+00  \n",
       "119  0.665343  0.091472      0.11       0.138311       0.000000e+00  \n",
       "..        ...       ...       ...            ...                ...  \n",
       "133  0.628913  0.082410      0.00       0.024683       0.000000e+00  \n",
       "131  0.628913  0.082410      0.00       0.024683       0.000000e+00  \n",
       "215  0.590776  0.103022      0.00       0.024919       0.000000e+00  \n",
       "226  0.626930  0.074792      0.00       0.020361       0.000000e+00  \n",
       "224  0.626930  0.074792      0.00       0.020361       0.000000e+00  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Cats.sort_values(by=[\"above_73\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce648612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats.to_csv(\"../data/NB_Cats_results_exhaust_raw6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf13195",
   "metadata": {},
   "source": [
    "Now we are talking, investigating into 47 might be worth our time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e18c3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2476    , 0.20470769],\n",
       "       [0.13386154, 0.41383077]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fold_acc=[]\n",
    "list_fold_f1=[]\n",
    "imp_record=None\n",
    "cmatrix_record=None\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "for train_index, test_index in splits: \n",
    "    x_tr,x_te=feat.iloc[train_index], feat.iloc[test_index]\n",
    "    y_tr, y_te=tar.iloc[train_index], tar.iloc[test_index]\n",
    "        \n",
    "    y_tr=np.ravel(y_tr.values)\n",
    "    y_te=np.ravel((y_te.values))\n",
    "        \n",
    "    cats=[dict_cat[key] for key in [\"X1\",\"X6\",\"above_4\"]]\n",
    "        \n",
    "    K=max(len(c) for c in cats)\n",
    "        \n",
    "    min_cats=[max(len(c), K + 1) for c in cats]\n",
    "        \n",
    "    pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=[\"X1\",\"X6\",\"above_4\"])),\n",
    "            (\"OrEncoder\", OrdinalEncoder(categories=cats,handle_unknown=\"use_encoded_value\",unknown_value=K,dtype=int)), \n",
    "            (\"NB\", CategoricalNB(min_categories=min_cats)),\n",
    "        ])\n",
    "    pipe.fit(X=x_tr,y=y_tr)\n",
    "    y_p=pipe.predict(X=x_te)\n",
    "    acc=accuracy_score(y_pred=y_p,y_true=y_te)\n",
    "    f1=f1_score(y_pred=y_p,y_true=y_te)\n",
    "    list_fold_acc.append(acc)\n",
    "    list_fold_f1.append(f1)\n",
    "    # with parallel_backend(\"threading\", n_jobs=-1):\n",
    "    #     with threadpool_limits(limits=1):\n",
    "    imp=permutation_importance(pipe,X=x_te.copy(deep=True),y=y_te,scoring=\"accuracy\",n_repeats=30,n_jobs=-1,random_state=420)\n",
    "    if imp_record is None: \n",
    "        imp_record=imp.importances_mean\n",
    "    else: \n",
    "        imp_record=imp_record+imp.importances_mean\n",
    "    cmatrix=confusion_matrix(y_pred=y_p,y_true=y_te)\n",
    "    cmatrix=cmatrix/np.sum(cmatrix)\n",
    "    if cmatrix_record is None: \n",
    "        cmatrix_record=cmatrix\n",
    "    else: \n",
    "        cmatrix_record=cmatrix_record+cmatrix\n",
    "    \n",
    "\n",
    "plt.hist(list_fold_acc,bins=25)\n",
    "plt.show()\n",
    "\n",
    "imp_record=imp_record/len(splits)\n",
    "imp_sort_index=imp_record.argsort()\n",
    "plt.barh(feat.columns[imp_sort_index], imp_record[imp_sort_index])\n",
    "plt.title(\"Feature importance by permutaion method\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "cmatrix_record=cmatrix_record/len(splits)\n",
    "cmatrix_record #This is the \"Average confusion matrix\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b475e",
   "metadata": {},
   "source": [
    "It is interesting how X6 is present in the selected features, yet have the least importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c00be2",
   "metadata": {},
   "source": [
    "### Categorical: with 5 raw features (removing X6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131977bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1  X2  X3  X4  X5  above_3  above_4  above_5  count_1  count_2  count_3  \\\n",
       "0     3   3   3   4   2      0.8      0.2      0.0        0        1        3   \n",
       "1     3   2   3   5   4      0.8      0.4      0.2        0        1        2   \n",
       "2     5   3   3   3   3      1.0      0.2      0.2        0        0        4   \n",
       "3     5   4   3   3   3      1.0      0.4      0.2        0        0        3   \n",
       "4     5   4   3   3   3      1.0      0.4      0.2        0        0        3   \n",
       "..   ..  ..  ..  ..  ..      ...      ...      ...      ...      ...      ...   \n",
       "121   5   2   3   4   4      0.8      0.6      0.2        0        1        1   \n",
       "122   5   2   3   4   2      0.6      0.4      0.2        0        2        1   \n",
       "123   5   3   3   4   4      1.0      0.6      0.2        0        0        2   \n",
       "124   4   3   3   4   4      1.0      0.6      0.0        0        0        2   \n",
       "125   5   3   2   5   5      0.8      0.6      0.6        0        1        1   \n",
       "\n",
       "     count_4  count_5  \n",
       "0          1        0  \n",
       "1          1        1  \n",
       "2          0        1  \n",
       "3          1        1  \n",
       "4          1        1  \n",
       "..       ...      ...  \n",
       "121        2        1  \n",
       "122        1        1  \n",
       "123        2        1  \n",
       "124        3        0  \n",
       "125        0        3  \n",
       "\n",
       "[126 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/raw.csv\")\n",
    "features=[feature for feature in list(df.columns)[1:] if feature not in [\"X6\"]] \n",
    "target=[\"Y\"]\n",
    "feat5=df[features]\n",
    "tar=df[target]\n",
    "# x_t, x_v, y_t, y_v= train_test_split(feat,tar, test_size=0.2, random_state=0, stratify=tar[\"Y\"])\n",
    "n_splits=5\n",
    "\n",
    "eva_feat=training.data_creator(counts=True)\n",
    "eva_feat_out=eva_feat.fit(X=feat5,y=tar).transform(X=feat5)\n",
    "all_cat_feat=[feature for feature in eva_feat_out.columns if feature not in [\"F_w_mean\",\"mean\"]] \n",
    "eva_feat_out=eva_feat_out[all_cat_feat]\n",
    "eva_feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4caae3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [np.int64(1), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X2': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X3': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X4': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X5': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'above_3': [np.float64(0.2),\n",
       "  np.float64(0.4),\n",
       "  np.float64(0.6),\n",
       "  np.float64(0.8),\n",
       "  np.float64(1.0)],\n",
       " 'above_4': [np.float64(0.0),\n",
       "  np.float64(0.2),\n",
       "  np.float64(0.4),\n",
       "  np.float64(0.6),\n",
       "  np.float64(0.8),\n",
       "  np.float64(1.0)],\n",
       " 'above_5': [np.float64(0.0),\n",
       "  np.float64(0.2),\n",
       "  np.float64(0.4),\n",
       "  np.float64(0.6),\n",
       "  np.float64(0.8),\n",
       "  np.float64(1.0)],\n",
       " 'count_1': [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)],\n",
       " 'count_2': [np.int64(0), np.int64(1), np.int64(2), np.int64(3)],\n",
       " 'count_3': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)],\n",
       " 'count_4': [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)],\n",
       " 'count_5': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat=dict()\n",
    "for key in eva_feat_out.columns: \n",
    "    dict_cat[key]=sorted(list(eva_feat_out[key].unique()))\n",
    "dict_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70170293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'above_3', 'above_4', 'above_5', 'count_3',\n",
       "       'count_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel=training.data_selector(how=\"or\")\n",
    "eva_sel_out=eva_sel.fit(X=eva_feat_out,y=tar).transform(X=eva_feat_out)\n",
    "eva_sel_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e45351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.270673</td>\n",
       "      <td>0.472968</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>-0.292175</td>\n",
       "      <td>-0.044343</td>\n",
       "      <td>-0.326948</td>\n",
       "      <td>-0.076642</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.438493</td>\n",
       "      <td>0.674558</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>-0.355576</td>\n",
       "      <td>-0.188990</td>\n",
       "      <td>-0.428509</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503943</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>-0.317259</td>\n",
       "      <td>-0.308125</td>\n",
       "      <td>-0.306736</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.089131</td>\n",
       "      <td>0.298694</td>\n",
       "      <td>0.270673</td>\n",
       "      <td>0.532007</td>\n",
       "      <td>0.438493</td>\n",
       "      <td>0.352353</td>\n",
       "      <td>0.503943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463479</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>-0.617939</td>\n",
       "      <td>-0.622983</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.093310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>above_4</td>\n",
       "      <td>4.790423</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>0.472968</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.674558</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.463479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>-0.302831</td>\n",
       "      <td>-0.272393</td>\n",
       "      <td>-0.769666</td>\n",
       "      <td>0.465047</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.192861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.574782</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_3</td>\n",
       "      <td>2.686108</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>-0.326948</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>-0.428509</td>\n",
       "      <td>-0.348061</td>\n",
       "      <td>-0.306736</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>-0.769666</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.111023</td>\n",
       "      <td>-0.148248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.337517</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.145612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.574782</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features    f score   p value        X1        X2        X3        X4  \\\n",
       "0        X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "2        X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "4        X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5   above_3   1.089131  0.298694  0.270673  0.532007  0.438493  0.352353   \n",
       "6   above_4   4.790423  0.030492  0.472968  0.312166  0.674558  0.545425   \n",
       "7   above_5   6.574782  0.011537  0.540798  0.262926  0.509864  0.413352   \n",
       "10  count_3   2.686108  0.103762 -0.326948  0.038807 -0.428509 -0.348061   \n",
       "12  count_5   6.574782  0.011537  0.540798  0.262926  0.509864  0.413352   \n",
       "\n",
       "          X5   above_3   above_4   above_5   count_1   count_2   count_3  \\\n",
       "0   0.432772  0.270673  0.472968  0.540798 -0.292175 -0.044343 -0.326948   \n",
       "2   0.358397  0.438493  0.674558  0.509864 -0.355576 -0.188990 -0.428509   \n",
       "4   1.000000  0.503943  0.606947  0.577781 -0.317259 -0.308125 -0.306736   \n",
       "5   0.503943  1.000000  0.463479  0.229849 -0.617939 -0.622983  0.209009   \n",
       "6   0.606947  0.463479  1.000000  0.553435 -0.302831 -0.272393 -0.769666   \n",
       "7   0.577781  0.229849  0.553435  1.000000 -0.112808 -0.172268 -0.445166   \n",
       "10 -0.306736  0.209009 -0.769666 -0.445166 -0.111023 -0.148248  1.000000   \n",
       "12  0.577781  0.229849  0.553435  1.000000 -0.112808 -0.172268 -0.445166   \n",
       "\n",
       "     count_4   count_5         Y  \n",
       "0  -0.076642  0.540798  0.280160  \n",
       "2   0.168572  0.509864  0.150838  \n",
       "4   0.025168  0.577781  0.224522  \n",
       "5   0.243872  0.229849  0.093310  \n",
       "6   0.465047  0.553435  0.192861  \n",
       "7  -0.479975  1.000000  0.224394  \n",
       "10 -0.337517 -0.445166 -0.145612  \n",
       "12 -0.479975  1.000000  0.224394  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.sel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ddfda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.270673</td>\n",
       "      <td>0.472968</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>-0.292175</td>\n",
       "      <td>-0.044343</td>\n",
       "      <td>-0.326948</td>\n",
       "      <td>-0.076642</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.532007</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>-0.462624</td>\n",
       "      <td>-0.198235</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>-0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.438493</td>\n",
       "      <td>0.674558</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>-0.355576</td>\n",
       "      <td>-0.188990</td>\n",
       "      <td>-0.428509</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.352353</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>-0.282620</td>\n",
       "      <td>-0.154952</td>\n",
       "      <td>-0.348061</td>\n",
       "      <td>0.135140</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503943</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>-0.317259</td>\n",
       "      <td>-0.308125</td>\n",
       "      <td>-0.306736</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.089131</td>\n",
       "      <td>0.298694</td>\n",
       "      <td>0.270673</td>\n",
       "      <td>0.532007</td>\n",
       "      <td>0.438493</td>\n",
       "      <td>0.352353</td>\n",
       "      <td>0.503943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463479</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>-0.617939</td>\n",
       "      <td>-0.622983</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.093310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>above_4</td>\n",
       "      <td>4.790423</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>0.472968</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.674558</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.463479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>-0.302831</td>\n",
       "      <td>-0.272393</td>\n",
       "      <td>-0.769666</td>\n",
       "      <td>0.465047</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.192861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.574782</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.675666</td>\n",
       "      <td>0.412661</td>\n",
       "      <td>-0.292175</td>\n",
       "      <td>-0.462624</td>\n",
       "      <td>-0.355576</td>\n",
       "      <td>-0.282620</td>\n",
       "      <td>-0.317259</td>\n",
       "      <td>-0.617939</td>\n",
       "      <td>-0.302831</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.230048</td>\n",
       "      <td>-0.111023</td>\n",
       "      <td>-0.199066</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>-0.073617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.221801</td>\n",
       "      <td>0.638498</td>\n",
       "      <td>-0.044343</td>\n",
       "      <td>-0.198235</td>\n",
       "      <td>-0.188990</td>\n",
       "      <td>-0.154952</td>\n",
       "      <td>-0.308125</td>\n",
       "      <td>-0.622983</td>\n",
       "      <td>-0.272393</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.230048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148248</td>\n",
       "      <td>-0.103806</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.042255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_3</td>\n",
       "      <td>2.686108</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>-0.326948</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>-0.428509</td>\n",
       "      <td>-0.348061</td>\n",
       "      <td>-0.306736</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>-0.769666</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.111023</td>\n",
       "      <td>-0.148248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.337517</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.145612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.155319</td>\n",
       "      <td>0.694181</td>\n",
       "      <td>-0.076642</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>0.135140</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>0.465047</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>-0.199066</td>\n",
       "      <td>-0.103806</td>\n",
       "      <td>-0.337517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>-0.035370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.574782</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.540798</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.509864</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.229849</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>-0.172268</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>-0.479975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features    f score   p value        X1        X2        X3        X4  \\\n",
       "0        X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "1        X2   0.073108  0.787313  0.059797  1.000000  0.184129  0.114838   \n",
       "2        X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "3        X4   0.516657  0.473623  0.087541  0.114838  0.302618  1.000000   \n",
       "4        X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5   above_3   1.089131  0.298694  0.270673  0.532007  0.438493  0.352353   \n",
       "6   above_4   4.790423  0.030492  0.472968  0.312166  0.674558  0.545425   \n",
       "7   above_5   6.574782  0.011537  0.540798  0.262926  0.509864  0.413352   \n",
       "8   count_1   0.675666  0.412661 -0.292175 -0.462624 -0.355576 -0.282620   \n",
       "9   count_2   0.221801  0.638498 -0.044343 -0.198235 -0.188990 -0.154952   \n",
       "10  count_3   2.686108  0.103762 -0.326948  0.038807 -0.428509 -0.348061   \n",
       "11  count_4   0.155319  0.694181 -0.076642  0.049337  0.168572  0.135140   \n",
       "12  count_5   6.574782  0.011537  0.540798  0.262926  0.509864  0.413352   \n",
       "\n",
       "          X5   above_3   above_4   above_5   count_1   count_2   count_3  \\\n",
       "0   0.432772  0.270673  0.472968  0.540798 -0.292175 -0.044343 -0.326948   \n",
       "1   0.039996  0.532007  0.312166  0.262926 -0.462624 -0.198235  0.038807   \n",
       "2   0.358397  0.438493  0.674558  0.509864 -0.355576 -0.188990 -0.428509   \n",
       "3   0.293115  0.352353  0.545425  0.413352 -0.282620 -0.154952 -0.348061   \n",
       "4   1.000000  0.503943  0.606947  0.577781 -0.317259 -0.308125 -0.306736   \n",
       "5   0.503943  1.000000  0.463479  0.229849 -0.617939 -0.622983  0.209009   \n",
       "6   0.606947  0.463479  1.000000  0.553435 -0.302831 -0.272393 -0.769666   \n",
       "7   0.577781  0.229849  0.553435  1.000000 -0.112808 -0.172268 -0.445166   \n",
       "8  -0.317259 -0.617939 -0.302831 -0.112808  1.000000 -0.230048 -0.111023   \n",
       "9  -0.308125 -0.622983 -0.272393 -0.172268 -0.230048  1.000000 -0.148248   \n",
       "10 -0.306736  0.209009 -0.769666 -0.445166 -0.111023 -0.148248  1.000000   \n",
       "11  0.025168  0.243872  0.465047 -0.479975 -0.199066 -0.103806 -0.337517   \n",
       "12  0.577781  0.229849  0.553435  1.000000 -0.112808 -0.172268 -0.445166   \n",
       "\n",
       "     count_4   count_5         Y  \n",
       "0  -0.076642  0.540798  0.280160  \n",
       "1   0.049337  0.262926 -0.024274  \n",
       "2   0.168572  0.509864  0.150838  \n",
       "3   0.135140  0.413352  0.064415  \n",
       "4   0.025168  0.577781  0.224522  \n",
       "5   0.243872  0.229849  0.093310  \n",
       "6   0.465047  0.553435  0.192861  \n",
       "7  -0.479975  1.000000  0.224394  \n",
       "8  -0.199066 -0.112808 -0.073617  \n",
       "9  -0.103806 -0.172268 -0.042255  \n",
       "10 -0.337517 -0.445166 -0.145612  \n",
       "11  1.000000 -0.479975 -0.035370  \n",
       "12 -0.479975  1.000000  0.224394  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a4e69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feats=list(eva_sel_out.columns)\n",
    "range_feat5_combin = training.all_combin(count_feats)\n",
    "model_choice={\n",
    "    \"Categorical\": None\n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "splits = list(RSKF.split(X=feat5, y=tar))\n",
    "\n",
    "pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelector\", training.data_selector()),\n",
    "            (\"OrEncoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\",dtype=int)), \n",
    "            (\"NB\", CategoricalNB()),\n",
    "        ])\n",
    "\n",
    "jobs5 = list(itertools.product(range_feat5_combin, model_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1fabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 255 | elapsed:  4.3min remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 255 out of 255 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(training.evaluate_combo)(\n",
    "        list_f_sel_tuple=feat_sel, \n",
    "        dict_param={\"OrEncoder__categories\": [dict_cat[key] for key in feat_sel], \n",
    "                    \"OrEncoder__unknown_value\": max(len(c) for c in [dict_cat[key] for key in feat_sel]), \n",
    "                    \"NB__min_categories\": [max(len(c), max(len(c) for c in [dict_cat[key] for key in feat_sel]) + 1) for c in [dict_cat[key] for key in feat_sel]]}, \n",
    "        splits=splits, \n",
    "        pipe=pipe, \n",
    "        feat=feat5, \n",
    "        tar=tar \n",
    "    )\n",
    "    for feat_sel, nn in jobs5\n",
    ")\n",
    "\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [\"Categorical\" for r in results] \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b12c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade2cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats.to_csv(\"../data/NB_Cats_results_exhaust_raw5X6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13aa7eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.638292</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.148064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.544457</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.546246</td>\n",
       "      <td>0.076622</td>\n",
       "      <td>0.637683</td>\n",
       "      <td>0.090683</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.552692</td>\n",
       "      <td>0.046719</td>\n",
       "      <td>0.690868</td>\n",
       "      <td>0.037869</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.640646</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>0.073216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>X1,X3,X5,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.614354</td>\n",
       "      <td>0.074149</td>\n",
       "      <td>0.636498</td>\n",
       "      <td>0.081227</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.059422</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>X1,X3,above_3,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.612415</td>\n",
       "      <td>0.077859</td>\n",
       "      <td>0.636100</td>\n",
       "      <td>0.083684</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.065493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>X1,X5,above_3,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.608400</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.631976</td>\n",
       "      <td>0.081729</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.050266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>X3,X5,above_3,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.575015</td>\n",
       "      <td>0.086323</td>\n",
       "      <td>0.613270</td>\n",
       "      <td>0.094327</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>X1,X3,X5,above_3,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.628285</td>\n",
       "      <td>0.082170</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.047846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features        model  acc_mean  \\\n",
       "0                                                  X1  Categorical  0.638292   \n",
       "1                                                  X3  Categorical  0.504354   \n",
       "2                                                  X5  Categorical  0.546246   \n",
       "3                                             above_3  Categorical  0.552692   \n",
       "4                                             above_4  Categorical  0.640646   \n",
       "..                                                ...          ...       ...   \n",
       "250          X1,X3,X5,above_4,above_5,count_3,count_5  Categorical  0.614354   \n",
       "251     X1,X3,above_3,above_4,above_5,count_3,count_5  Categorical  0.612415   \n",
       "252     X1,X5,above_3,above_4,above_5,count_3,count_5  Categorical  0.608400   \n",
       "253     X3,X5,above_3,above_4,above_5,count_3,count_5  Categorical  0.575015   \n",
       "254  X1,X3,X5,above_3,above_4,above_5,count_3,count_5  Categorical  0.604800   \n",
       "\n",
       "      acc_std   f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "0    0.087778  0.661949  0.088259      0.15       0.148064                0.0  \n",
       "1    0.063451  0.544457  0.093973      0.00       0.000188                0.0  \n",
       "2    0.076622  0.637683  0.090683      0.00       0.008239                0.0  \n",
       "3    0.046719  0.690868  0.037869      0.00       0.000074                0.0  \n",
       "4    0.076210  0.682859  0.073216      0.11       0.120503                0.0  \n",
       "..        ...       ...       ...       ...            ...                ...  \n",
       "250  0.074149  0.636498  0.081227      0.04       0.059422                0.0  \n",
       "251  0.077859  0.636100  0.083684      0.05       0.065493                0.0  \n",
       "252  0.074043  0.631976  0.081729      0.04       0.050266                0.0  \n",
       "253  0.086323  0.613270  0.094327      0.02       0.036295                0.0  \n",
       "254  0.075145  0.628285  0.082170      0.03       0.047846                0.0  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Cats.sort_values(by=[\"acc_mean_above_73\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ec63b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.614092</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.724160</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.032611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>above_3,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.607123</td>\n",
       "      <td>0.060521</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>X1,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.658554</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>0.700129</td>\n",
       "      <td>0.077183</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.183907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X1,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.648554</td>\n",
       "      <td>0.080859</td>\n",
       "      <td>0.694055</td>\n",
       "      <td>0.080749</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.156903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X1,above_3,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.645908</td>\n",
       "      <td>0.078876</td>\n",
       "      <td>0.693384</td>\n",
       "      <td>0.076153</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.143181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>X3,above_5,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.528477</td>\n",
       "      <td>0.075853</td>\n",
       "      <td>0.551676</td>\n",
       "      <td>0.097706</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>X3,above_3,above_5,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>0.546663</td>\n",
       "      <td>0.089819</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>above_3,above_5,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.526369</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.544528</td>\n",
       "      <td>0.109591</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.544457</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>above_5,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.531923</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>0.535086</td>\n",
       "      <td>0.132893</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features        model  acc_mean   acc_std   f1_mean  \\\n",
       "6                       count_3  Categorical  0.614092  0.062866  0.724160   \n",
       "28              above_3,count_3  Categorical  0.607123  0.060521  0.705403   \n",
       "52           X1,above_4,count_3  Categorical  0.658554  0.079334  0.700129   \n",
       "11                   X1,above_4  Categorical  0.648554  0.080859  0.694055   \n",
       "118  X1,above_3,above_4,count_3  Categorical  0.645908  0.078876  0.693384   \n",
       "..                          ...          ...       ...       ...       ...   \n",
       "70           X3,above_5,count_5  Categorical  0.528477  0.075853  0.551676   \n",
       "141  X3,above_3,above_5,count_5  Categorical  0.515800  0.076351  0.546663   \n",
       "86      above_3,above_5,count_5  Categorical  0.526369  0.077319  0.544528   \n",
       "1                            X3  Categorical  0.504354  0.063451  0.544457   \n",
       "34              above_5,count_5  Categorical  0.531923  0.076512  0.535086   \n",
       "\n",
       "       f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "6    0.055599      0.01       0.032611                0.0  \n",
       "28   0.051783      0.02       0.021163                0.0  \n",
       "52   0.077183      0.16       0.183907                0.0  \n",
       "11   0.080749      0.10       0.156903                0.0  \n",
       "118  0.076153      0.12       0.143181                0.0  \n",
       "..        ...       ...            ...                ...  \n",
       "70   0.097706      0.00       0.003945                0.0  \n",
       "141  0.089819      0.00       0.002512                0.0  \n",
       "86   0.109591      0.00       0.004224                0.0  \n",
       "1    0.093973      0.00       0.000188                0.0  \n",
       "34   0.132893      0.00       0.004815                0.0  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Cats.sort_values(by=[\"f1_mean\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6b6104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>X1,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.658554</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>0.700129</td>\n",
       "      <td>0.077183</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.183907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X1,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.648554</td>\n",
       "      <td>0.080859</td>\n",
       "      <td>0.694055</td>\n",
       "      <td>0.080749</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.156903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>X1,X3,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.647523</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>0.685583</td>\n",
       "      <td>0.075882</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.151844</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X1,above_3,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.645908</td>\n",
       "      <td>0.078876</td>\n",
       "      <td>0.693384</td>\n",
       "      <td>0.076153</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.143181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X1,above_3,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.643062</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.074398</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.115638</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>X3,above_3,above_5,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>0.546663</td>\n",
       "      <td>0.089819</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>above_3,above_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.515708</td>\n",
       "      <td>0.080616</td>\n",
       "      <td>0.579730</td>\n",
       "      <td>0.085365</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>above_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.515708</td>\n",
       "      <td>0.080616</td>\n",
       "      <td>0.579730</td>\n",
       "      <td>0.085365</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.544457</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X3,above_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>0.566284</td>\n",
       "      <td>0.096228</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features        model  acc_mean   acc_std   f1_mean  \\\n",
       "52           X1,above_4,count_3  Categorical  0.658554  0.079334  0.700129   \n",
       "11                   X1,above_4  Categorical  0.648554  0.080859  0.694055   \n",
       "38                X1,X3,above_4  Categorical  0.647523  0.080187  0.685583   \n",
       "118  X1,above_3,above_4,count_3  Categorical  0.645908  0.078876  0.693384   \n",
       "47           X1,above_3,above_4  Categorical  0.643062  0.072626  0.692698   \n",
       "..                          ...          ...       ...       ...       ...   \n",
       "141  X3,above_3,above_5,count_5  Categorical  0.515800  0.076351  0.546663   \n",
       "27              above_3,above_5  Categorical  0.515708  0.080616  0.579730   \n",
       "29              above_3,count_5  Categorical  0.515708  0.080616  0.579730   \n",
       "1                            X3  Categorical  0.504354  0.063451  0.544457   \n",
       "16                   X3,above_3  Categorical  0.501400  0.074483  0.566284   \n",
       "\n",
       "       f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "52   0.077183      0.16       0.183907                0.0  \n",
       "11   0.080749      0.10       0.156903                0.0  \n",
       "38   0.075882      0.10       0.151844                0.0  \n",
       "118  0.076153      0.12       0.143181                0.0  \n",
       "47   0.074398      0.09       0.115638                0.0  \n",
       "..        ...       ...            ...                ...  \n",
       "141  0.089819      0.00       0.002512                0.0  \n",
       "27   0.085365      0.00       0.003928                0.0  \n",
       "29   0.085365      0.00       0.003928                0.0  \n",
       "1    0.093973      0.00       0.000188                0.0  \n",
       "16   0.096228      0.00       0.001073                0.0  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Cats.sort_values(by=[\"acc_mean\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d797d951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25438462 0.19792308]\n",
      " [0.14352308 0.40416923]]\n"
     ]
    }
   ],
   "source": [
    "#52\n",
    "n_split = 5 \n",
    "n_repeats = 20\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "splits = list(RSKF.split(X=feat5, y=tar))\n",
    "\n",
    "pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelector\", training.data_selector()),\n",
    "            (\"OrEncoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\",dtype=int)), \n",
    "            (\"NB\", CategoricalNB()),\n",
    "        ])\n",
    "\n",
    "feat_sel=[\"X1\",\"above_4\",\"count_3\"]\n",
    "dict_param={\"DataSelector__force\": feat_sel, \n",
    "            \"OrEncoder__categories\": [dict_cat[key] for key in feat_sel], \n",
    "            \"OrEncoder__unknown_value\": max(len(c) for c in [dict_cat[key] for key in feat_sel]), \n",
    "            \"NB__min_categories\": [max(len(c), max(len(c) for c in [dict_cat[key] for key in feat_sel]) + 1) for c in [dict_cat[key] for key in feat_sel]]}\n",
    "pipe.set_params(**dict_param) \n",
    "\n",
    "training.show_result(splits=splits, pipe=pipe, feat=feat5, tar=tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4863f",
   "metadata": {},
   "source": [
    "There is clear decrease in performance, I do not see reason to continue investigating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cccbc0d",
   "metadata": {},
   "source": [
    "## Result (Best for NB): Use all raw features, Categorical NB, forced manufactured features X1,X6,above_4. See at 427 in \"Categorical\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fcbd598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X1,X6,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.661431</td>\n",
       "      <td>0.092942</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>0.094698</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.230330</td>\n",
       "      <td>8.060219e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.544457</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.638292</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.148064</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X6</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.611154</td>\n",
       "      <td>0.066944</td>\n",
       "      <td>0.719661</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.037923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.628877</td>\n",
       "      <td>0.072537</td>\n",
       "      <td>0.678397</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>X1,X3,X5,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.590815</td>\n",
       "      <td>0.073209</td>\n",
       "      <td>0.622893</td>\n",
       "      <td>0.076275</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>X1,X3,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.592877</td>\n",
       "      <td>0.078893</td>\n",
       "      <td>0.627129</td>\n",
       "      <td>0.080832</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>X1,X5,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.598785</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.629939</td>\n",
       "      <td>0.077708</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>X3,X5,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.582323</td>\n",
       "      <td>0.078241</td>\n",
       "      <td>0.621857</td>\n",
       "      <td>0.087883</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>X1,X3,X5,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>0.073626</td>\n",
       "      <td>0.624918</td>\n",
       "      <td>0.075432</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        features        model  acc_mean  \\\n",
       "47                                 X1,X6,above_4  Categorical  0.661431   \n",
       "1                                             X3  Categorical  0.504354   \n",
       "0                                             X1  Categorical  0.638292   \n",
       "3                                             X6  Categorical  0.611154   \n",
       "4                                        above_4  Categorical  0.628877   \n",
       "..                                           ...          ...       ...   \n",
       "250     X1,X3,X5,above_4,above_5,count_3,count_5  Categorical  0.590815   \n",
       "251     X1,X3,X6,above_4,above_5,count_3,count_5  Categorical  0.592877   \n",
       "252     X1,X5,X6,above_4,above_5,count_3,count_5  Categorical  0.598785   \n",
       "253     X3,X5,X6,above_4,above_5,count_3,count_5  Categorical  0.582323   \n",
       "254  X1,X3,X5,X6,above_4,above_5,count_3,count_5  Categorical  0.592415   \n",
       "\n",
       "      acc_std   f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "47   0.092942  0.704892  0.094698      0.24       0.230330       8.060219e-14  \n",
       "1    0.063451  0.544457  0.093973      0.00       0.000188       0.000000e+00  \n",
       "0    0.087778  0.661949  0.088259      0.15       0.148064       0.000000e+00  \n",
       "3    0.066944  0.719661  0.049947      0.05       0.037923       0.000000e+00  \n",
       "4    0.072537  0.678397  0.063714      0.06       0.081646       0.000000e+00  \n",
       "..        ...       ...       ...       ...            ...                ...  \n",
       "250  0.073209  0.622893  0.076275      0.01       0.028639       0.000000e+00  \n",
       "251  0.078893  0.627129  0.080832      0.03       0.041097       0.000000e+00  \n",
       "252  0.071703  0.629939  0.077708      0.02       0.033626       0.000000e+00  \n",
       "253  0.078241  0.621857  0.087883      0.01       0.029550       0.000000e+00  \n",
       "254  0.073626  0.624918  0.075432      0.02       0.030833       0.000000e+00  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best=pd.read_csv(\"../data/NB_Cats_results_exhaust_raw6.csv\")\n",
    "df_best.sort_values(by=[\"acc_mean_above_73\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
