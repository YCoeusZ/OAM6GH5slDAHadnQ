{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324c3505",
   "metadata": {},
   "source": [
    "# Naive Bayesian methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "957014da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import f_classif\n",
    "import itertools\n",
    "import sys\n",
    "import importlib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OrdinalEncoder\n",
    "# from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, make_scorer\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from threadpoolctl import threadpool_limits\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import norm, t\n",
    "from sklearn.base import clone \n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training\n",
    "importlib.reload(training);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2f6d4",
   "metadata": {},
   "source": [
    "## Data importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9027140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/raw.csv\")\n",
    "features=list(df.columns)[1:]\n",
    "target=[\"Y\"]\n",
    "feat=df[features]\n",
    "tar=df[target]\n",
    "# x_t, x_v, y_t, y_v= train_test_split(feat,tar, test_size=0.2, random_state=0, stratify=tar[\"Y\"])\n",
    "n_splits=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0148b",
   "metadata": {},
   "source": [
    "## For all raw features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a52551b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'X6', 'mean', 'F_w_mean', 'above_4', 'above_5',\n",
       "       'count_3', 'count_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe=Pipeline([(\"DataCreater\", training.data_creator(counts=True)),(\"DataSelector\",training.data_selector())])\n",
    "tar_arr=np.ravel(tar.values)\n",
    "eva_pipe.fit(X=feat,y=tar)\n",
    "eva_out=eva_pipe.transform(X=feat)\n",
    "eva_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75b56888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>mean</th>\n",
       "      <th>F_w_mean</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.306094</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.235885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F_w_mean</td>\n",
       "      <td>12.615311</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.303878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features    f score   p value        X1        X2        X3        X4  \\\n",
       "0         X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "2         X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "4         X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5         X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6       mean   7.306094  0.007836  0.607460  0.426097  0.676149  0.557803   \n",
       "7   F_w_mean  12.615311  0.000542  0.834641  0.078909  0.532371  0.298662   \n",
       "9    above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "10   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "13   count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "15   count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6      mean  F_w_mean   above_3   above_4   above_5  \\\n",
       "0   0.432772  0.411873  0.607460  0.834641  0.266199  0.492355  0.604855   \n",
       "2   0.358397  0.203750  0.676149  0.532371  0.442280  0.638649  0.481689   \n",
       "4   1.000000  0.320195  0.712786  0.806779  0.491804  0.616787  0.586695   \n",
       "5   0.320195  1.000000  0.540096  0.574523  0.261704  0.458477  0.490605   \n",
       "6   0.712786  0.540096  1.000000  0.869373  0.687659  0.848710  0.773920   \n",
       "7   0.806779  0.574523  0.869373  1.000000  0.498831  0.743851  0.761327   \n",
       "9   0.616787  0.458477  0.848710  0.743851  0.465645  1.000000  0.546995   \n",
       "10  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "13 -0.343809 -0.327806 -0.465487 -0.480216  0.177713 -0.788134 -0.448806   \n",
       "15  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "\n",
       "     count_1   count_2   count_3   count_4   count_5         Y  \n",
       "0  -0.272144 -0.063015 -0.362352 -0.182806  0.604855  0.280160  \n",
       "2  -0.368676 -0.189451 -0.402565  0.097357  0.481689  0.150838  \n",
       "4  -0.292405 -0.330012 -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.275081 -0.054304 -0.327806 -0.090021  0.490605  0.167669  \n",
       "6  -0.557112 -0.310913 -0.465487 -0.018374  0.773920  0.235885  \n",
       "7  -0.397480 -0.232290 -0.480216 -0.107788  0.761327  0.303878  \n",
       "9  -0.306616 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "10 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "13 -0.103910 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "15 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe[\"DataSelector\"].sel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f6c34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>mean</th>\n",
       "      <th>F_w_mean</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>7.306094</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.607460</td>\n",
       "      <td>0.426097</td>\n",
       "      <td>0.676149</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.235885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F_w_mean</td>\n",
       "      <td>12.615311</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.834641</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0.806779</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.303878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.848710</td>\n",
       "      <td>0.743851</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.557112</td>\n",
       "      <td>-0.397480</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.310913</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.465487</td>\n",
       "      <td>-0.480216</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>-0.107788</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features    f score   p value        X1        X2        X3        X4  \\\n",
       "0         X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "1         X2   0.073108  0.787313  0.059797  1.000000  0.184129  0.114838   \n",
       "2         X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "3         X4   0.516657  0.473623  0.087541  0.114838  0.302618  1.000000   \n",
       "4         X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5         X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6       mean   7.306094  0.007836  0.607460  0.426097  0.676149  0.557803   \n",
       "7   F_w_mean  12.615311  0.000542  0.834641  0.078909  0.532371  0.298662   \n",
       "8    above_3   1.032794  0.311482  0.266199  0.500598  0.442280  0.383442   \n",
       "9    above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "10   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "11   count_1   0.457080  0.500251 -0.272144 -0.420657 -0.368676 -0.308409   \n",
       "12   count_2   0.366975  0.545765 -0.063015 -0.211012 -0.189451 -0.175639   \n",
       "13   count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "14   count_4   0.032071  0.858165 -0.182806  0.027148  0.097357  0.083189   \n",
       "15   count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6      mean  F_w_mean   above_3   above_4   above_5  \\\n",
       "0   0.432772  0.411873  0.607460  0.834641  0.266199  0.492355  0.604855   \n",
       "1   0.039996 -0.062205  0.426097  0.078909  0.500598  0.268810  0.215269   \n",
       "2   0.358397  0.203750  0.676149  0.532371  0.442280  0.638649  0.481689   \n",
       "3   0.293115  0.215888  0.557803  0.298662  0.383442  0.521454  0.389949   \n",
       "4   1.000000  0.320195  0.712786  0.806779  0.491804  0.616787  0.586695   \n",
       "5   0.320195  1.000000  0.540096  0.574523  0.261704  0.458477  0.490605   \n",
       "6   0.712786  0.540096  1.000000  0.869373  0.687659  0.848710  0.773920   \n",
       "7   0.806779  0.574523  0.869373  1.000000  0.498831  0.743851  0.761327   \n",
       "8   0.491804  0.261704  0.687659  0.498831  1.000000  0.465645  0.229256   \n",
       "9   0.616787  0.458477  0.848710  0.743851  0.465645  1.000000  0.546995   \n",
       "10  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "11 -0.292405 -0.275081 -0.557112 -0.397480 -0.639627 -0.306616 -0.129758   \n",
       "12 -0.330012 -0.054304 -0.310913 -0.232290 -0.625264 -0.282240 -0.160484   \n",
       "13 -0.343809 -0.327806 -0.465487 -0.480216  0.177713 -0.788134 -0.448806   \n",
       "14 -0.040143 -0.090021 -0.018374 -0.107788  0.205652  0.381294 -0.565327   \n",
       "15  0.586695  0.490605  0.773920  0.761327  0.229256  0.546995  1.000000   \n",
       "\n",
       "     count_1   count_2   count_3   count_4   count_5         Y  \n",
       "0  -0.272144 -0.063015 -0.362352 -0.182806  0.604855  0.280160  \n",
       "1  -0.420657 -0.211012  0.049254  0.027148  0.215269 -0.024274  \n",
       "2  -0.368676 -0.189451 -0.402565  0.097357  0.481689  0.150838  \n",
       "3  -0.308409 -0.175639 -0.313167  0.083189  0.389949  0.064415  \n",
       "4  -0.292405 -0.330012 -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.275081 -0.054304 -0.327806 -0.090021  0.490605  0.167669  \n",
       "6  -0.557112 -0.310913 -0.465487 -0.018374  0.773920  0.235885  \n",
       "7  -0.397480 -0.232290 -0.480216 -0.107788  0.761327  0.303878  \n",
       "8  -0.639627 -0.625264  0.177713  0.205652  0.229256  0.090886  \n",
       "9  -0.306616 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "10 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "11  1.000000 -0.199957 -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "12 -0.199957  1.000000 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "13 -0.103910 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "14 -0.158830 -0.100881 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "15 -0.129758 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_pipe[\"DataSelector\"].total_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f2d70",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c2f2e",
   "metadata": {},
   "source": [
    "Gaussian takes any value, so we will just send everything we believe will be helpful in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b76fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1023 out of 1023 | elapsed: 16.7min finished\n"
     ]
    }
   ],
   "source": [
    "range_feat_combin = training.all_combin(eva_out.columns)\n",
    "model_choice={\n",
    "    \"Gaussian\": GaussianNB()\n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"NB\", clone(model_choice[model_name])),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3efb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Gus = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9dd11d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>X3,X5,mean,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.611031</td>\n",
       "      <td>0.082613</td>\n",
       "      <td>0.655625</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.074922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>X1,X5,above_5,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.608231</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.616037</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.070716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>X1,X5,F_w_mean,above_5,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.608292</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.621565</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>X3,X5,mean,F_w_mean,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.648501</td>\n",
       "      <td>0.086814</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>X3,X5,mean,above_4,count_3</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.607815</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.084667</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>X1,X3,X5,X6,above_4,above_5,count_3,count_5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.086067</td>\n",
       "      <td>0.556404</td>\n",
       "      <td>0.100495</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>X1,X3,X6,mean,F_w_mean,above_4,above_5,count_3...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.520923</td>\n",
       "      <td>0.080230</td>\n",
       "      <td>0.545198</td>\n",
       "      <td>0.094876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>X1,X5,X6,mean,F_w_mean,above_4,above_5,count_3...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.544385</td>\n",
       "      <td>0.085483</td>\n",
       "      <td>0.567705</td>\n",
       "      <td>0.099150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X5</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.587569</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.670835</td>\n",
       "      <td>0.076213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>X1,X3,X5,X6,mean,F_w_mean,above_4,above_5,coun...</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.534369</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.557966</td>\n",
       "      <td>0.099476</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features     model  acc_mean  \\\n",
       "268                                  X3,X5,mean,count_3  Gaussian  0.611031   \n",
       "222                               X1,X5,above_5,count_5  Gaussian  0.608231   \n",
       "470                      X1,X5,F_w_mean,above_5,count_5  Gaussian  0.608292   \n",
       "528                         X3,X5,mean,F_w_mean,count_3  Gaussian  0.603846   \n",
       "531                          X3,X5,mean,above_4,count_3  Gaussian  0.607815   \n",
       "...                                                 ...       ...       ...   \n",
       "981         X1,X3,X5,X6,above_4,above_5,count_3,count_5  Gaussian  0.540785   \n",
       "1019  X1,X3,X6,mean,F_w_mean,above_4,above_5,count_3...  Gaussian  0.520923   \n",
       "1020  X1,X5,X6,mean,F_w_mean,above_4,above_5,count_3...  Gaussian  0.544385   \n",
       "2                                                    X5  Gaussian  0.587569   \n",
       "1022  X1,X3,X5,X6,mean,F_w_mean,above_4,above_5,coun...  Gaussian  0.534369   \n",
       "\n",
       "       acc_std   f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "268   0.082613  0.655625  0.083925      0.09       0.074922                0.0  \n",
       "222   0.082809  0.616037  0.100953      0.08       0.070716                0.0  \n",
       "470   0.081815  0.621565  0.097477      0.07       0.068429                0.0  \n",
       "528   0.083175  0.648501  0.086814      0.07       0.064668                0.0  \n",
       "531   0.081609  0.655354  0.084667      0.07       0.067172                0.0  \n",
       "...        ...       ...       ...       ...            ...                ...  \n",
       "981   0.086067  0.556404  0.100495      0.00       0.013958                0.0  \n",
       "1019  0.080230  0.545198  0.094876      0.00       0.004581                0.0  \n",
       "1020  0.085483  0.567705  0.099150      0.00       0.014951                0.0  \n",
       "2     0.070839  0.670835  0.076213      0.00       0.022183                0.0  \n",
       "1022  0.087555  0.557966  0.099476      0.00       0.012729                0.0  \n",
       "\n",
       "[1023 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Gus.sort_values(by=[\"above_73\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "082a0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Gus.to_csv(\"../data/NB_Gus_results_exhaust_raw6.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b813c",
   "metadata": {},
   "source": [
    "### Count intakes: Multinomial and Complement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a8734",
   "metadata": {},
   "source": [
    "Multinomial and complement methods takes counts and frequencies only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f401db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      above_3   above_4   above_5  count_1  count_2  count_3  count_4  count_5\n",
       "0    0.833333  0.333333  0.000000        0        1        3        2        0\n",
       "1    0.833333  0.333333  0.166667        0        1        3        1        1\n",
       "2    1.000000  0.333333  0.333333        0        0        4        0        2\n",
       "3    1.000000  0.500000  0.333333        0        0        3        1        2\n",
       "4    1.000000  0.500000  0.333333        0        0        3        1        2\n",
       "..        ...       ...       ...      ...      ...      ...      ...      ...\n",
       "121  0.833333  0.500000  0.166667        0        1        2        2        1\n",
       "122  0.666667  0.500000  0.333333        0        2        1        1        2\n",
       "123  1.000000  0.666667  0.333333        0        0        2        2        2\n",
       "124  1.000000  0.666667  0.166667        0        0        2        3        1\n",
       "125  0.833333  0.666667  0.666667        0        1        1        0        4\n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_feat=training.data_creator(counts=True)\n",
    "all_count_feat=[\"above_3\",\"above_4\",\"above_5\",\"count_1\", \"count_2\", \"count_3\", \"count_4\", \"count_5\"]\n",
    "eva_feat_out=eva_feat.fit(X=feat,y=tar).transform(X=feat)\n",
    "eva_feat_out=eva_feat_out[all_count_feat]\n",
    "eva_feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "376919b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['above_3', 'above_4', 'above_5', 'count_3', 'count_5'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel=training.data_selector(how=\"or\")\n",
    "eva_sel_out=eva_sel.fit(X=eva_feat_out,y=tar).transform(X=eva_feat_out)\n",
    "eva_sel_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8d13a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features   f score   p value   above_3   above_4   above_5   count_1  \\\n",
       "0  above_3  1.032794  0.311482  1.000000  0.465645  0.229256 -0.639627   \n",
       "1  above_4  7.194813  0.008308  0.465645  1.000000  0.546995 -0.306616   \n",
       "2  above_5  6.520675  0.011874  0.229256  0.546995  1.000000 -0.129758   \n",
       "3  count_1  0.457080  0.500251 -0.639627 -0.306616 -0.129758  1.000000   \n",
       "4  count_2  0.366975  0.545765 -0.625264 -0.282240 -0.160484 -0.199957   \n",
       "5  count_3  5.016985  0.026881  0.177713 -0.788134 -0.448806 -0.103910   \n",
       "6  count_4  0.032071  0.858165  0.205652  0.381294 -0.565327 -0.158830   \n",
       "7  count_5  6.520675  0.011874  0.229256  0.546995  1.000000 -0.129758   \n",
       "\n",
       "    count_2   count_3   count_4   count_5         Y  \n",
       "0 -0.625264  0.177713  0.205652  0.229256  0.090886  \n",
       "1 -0.282240 -0.788134  0.381294  0.546995  0.234181  \n",
       "2 -0.160484 -0.448806 -0.565327  1.000000  0.223515  \n",
       "3 -0.199957 -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "4  1.000000 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "5 -0.121027  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "6 -0.100881 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "7 -0.160484 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5ac9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  62 | elapsed:   47.1s remaining:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  62 | elapsed:   47.9s remaining:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  62 | elapsed:   59.7s remaining:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  62 | elapsed:  1.0min remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "count_feats=list(eva_sel_out.columns)\n",
    "range_feat_combin = training.all_combin(count_feats)\n",
    "model_choice={\n",
    "    \"Multinomial\": MultinomialNB(),\n",
    "    \"Complement\": ComplementNB() \n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"NB\", clone(model_choice[model_name])),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6af97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Counters = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bec6d909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>above_3,above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.625169</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.807641e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>above_5,count_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.578092</td>\n",
       "      <td>0.095263</td>\n",
       "      <td>0.536779</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.540021e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>above_5,count_3,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.594431</td>\n",
       "      <td>0.090290</td>\n",
       "      <td>0.584287</td>\n",
       "      <td>0.136699</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.661418e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.619569</td>\n",
       "      <td>0.060633</td>\n",
       "      <td>0.712132</td>\n",
       "      <td>0.048961</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.428163e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>count_3,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.136625</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.465733e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>above_3,above_4,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.548169</td>\n",
       "      <td>0.074767</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.508512e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>above_4,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.548062</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.703915</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.527702e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>above_3,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.549338</td>\n",
       "      <td>0.070298</td>\n",
       "      <td>0.649575</td>\n",
       "      <td>0.067834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.085565e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>above_3,above_4,above_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.707611</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>above_3,above_4,above_5,count_5</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.074828</td>\n",
       "      <td>0.643519</td>\n",
       "      <td>0.072263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.134050e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           features        model  acc_mean   acc_std  \\\n",
       "32          above_3,above_4,count_3  Multinomial  0.625169  0.063007   \n",
       "25                  above_5,count_3   Complement  0.578092  0.095263   \n",
       "49          above_5,count_3,count_5   Complement  0.594431  0.090290   \n",
       "20                  above_4,count_3  Multinomial  0.619569  0.060633   \n",
       "29                  count_3,count_5   Complement  0.594031  0.089642   \n",
       "..                              ...          ...       ...       ...   \n",
       "34          above_3,above_4,count_5  Multinomial  0.548169  0.074767   \n",
       "44          above_4,above_5,count_5  Multinomial  0.548062  0.033387   \n",
       "38          above_3,above_5,count_5  Multinomial  0.549338  0.070298   \n",
       "30          above_3,above_4,above_5  Multinomial  0.547692  0.016165   \n",
       "52  above_3,above_4,above_5,count_5  Multinomial  0.550200  0.074828   \n",
       "\n",
       "     f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "32  0.710032  0.052744      0.08   4.807641e-02                0.0  \n",
       "25  0.536779  0.146137      0.07   5.540021e-02                0.0  \n",
       "49  0.584287  0.136699      0.07   6.661418e-02                0.0  \n",
       "20  0.712132  0.048961      0.06   3.428163e-02                0.0  \n",
       "29  0.584214  0.136625      0.06   6.465733e-02                0.0  \n",
       "..       ...       ...       ...            ...                ...  \n",
       "34  0.645688  0.072604      0.00   7.508512e-03                0.0  \n",
       "44  0.703915  0.026137      0.00   2.527702e-08                0.0  \n",
       "38  0.649575  0.067834      0.00   5.085565e-03                0.0  \n",
       "30  0.707611  0.013610      0.00   0.000000e+00                0.0  \n",
       "52  0.643519  0.072263      0.00   8.134050e-03                0.0  \n",
       "\n",
       "[62 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Counters.sort_values(by=[\"above_73\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b59631a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>above_3,above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.625169</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>0.710032</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>above_4,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.619569</td>\n",
       "      <td>0.060633</td>\n",
       "      <td>0.712132</td>\n",
       "      <td>0.048961</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>above_3,above_5,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.609169</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.687830</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>above_4,above_5,count_3</td>\n",
       "      <td>Multinomial</td>\n",
       "      <td>0.598077</td>\n",
       "      <td>0.084128</td>\n",
       "      <td>0.665227</td>\n",
       "      <td>0.088955</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>above_5,count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.595215</td>\n",
       "      <td>0.081296</td>\n",
       "      <td>0.660414</td>\n",
       "      <td>0.073376</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.048663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>above_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above_4</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_5</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>above_3</td>\n",
       "      <td>Complement</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features        model  acc_mean   acc_std   f1_mean  \\\n",
       "32  above_3,above_4,count_3  Multinomial  0.625169  0.063007  0.710032   \n",
       "20          above_4,count_3  Multinomial  0.619569  0.060633  0.712132   \n",
       "36  above_3,above_5,count_3  Multinomial  0.609169  0.073740  0.687830   \n",
       "42  above_4,above_5,count_3  Multinomial  0.598077  0.084128  0.665227   \n",
       "27          above_5,count_5   Complement  0.595215  0.081296  0.660414   \n",
       "..                      ...          ...       ...       ...       ...   \n",
       "5                   above_5   Complement  0.452308  0.016165  0.000000   \n",
       "7                   count_3   Complement  0.452308  0.016165  0.000000   \n",
       "3                   above_4   Complement  0.452308  0.016165  0.000000   \n",
       "9                   count_5   Complement  0.452308  0.016165  0.000000   \n",
       "1                   above_3   Complement  0.452308  0.016165  0.000000   \n",
       "\n",
       "      f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "32  0.052744      0.08       0.048076                0.0  \n",
       "20  0.048961      0.06       0.034282                0.0  \n",
       "36  0.070713      0.04       0.050648                0.0  \n",
       "42  0.088955      0.05       0.058425                0.0  \n",
       "27  0.073376      0.03       0.048663                0.0  \n",
       "..       ...       ...            ...                ...  \n",
       "5   0.000000      0.00       0.000000                0.0  \n",
       "7   0.000000      0.00       0.000000                0.0  \n",
       "3   0.000000      0.00       0.000000                0.0  \n",
       "9   0.000000      0.00       0.000000                0.0  \n",
       "1   0.000000      0.00       0.000000                0.0  \n",
       "\n",
       "[62 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Counters.sort_values(by=[\"acc_mean\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93561d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Counters.to_csv(\"../data/NB_Counter_exhaust_raw6.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e9877",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718119",
   "metadata": {},
   "source": [
    "We will remove the features that are not categorical (or simply has too many categories). And we will add a OrdinalEncoder layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91bf82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1  X2  X3  X4  X5  X6   above_3   above_4   above_5  count_1  count_2  \\\n",
       "0     3   3   3   4   2   4  0.833333  0.333333  0.000000        0        1   \n",
       "1     3   2   3   5   4   3  0.833333  0.333333  0.166667        0        1   \n",
       "2     5   3   3   3   3   5  1.000000  0.333333  0.333333        0        0   \n",
       "3     5   4   3   3   3   5  1.000000  0.500000  0.333333        0        0   \n",
       "4     5   4   3   3   3   5  1.000000  0.500000  0.333333        0        0   \n",
       "..   ..  ..  ..  ..  ..  ..       ...       ...       ...      ...      ...   \n",
       "121   5   2   3   4   4   3  0.833333  0.500000  0.166667        0        1   \n",
       "122   5   2   3   4   2   5  0.666667  0.500000  0.333333        0        2   \n",
       "123   5   3   3   4   4   5  1.000000  0.666667  0.333333        0        0   \n",
       "124   4   3   3   4   4   5  1.000000  0.666667  0.166667        0        0   \n",
       "125   5   3   2   5   5   5  0.833333  0.666667  0.666667        0        1   \n",
       "\n",
       "     count_3  count_4  count_5  \n",
       "0          3        2        0  \n",
       "1          3        1        1  \n",
       "2          4        0        2  \n",
       "3          3        1        2  \n",
       "4          3        1        2  \n",
       "..       ...      ...      ...  \n",
       "121        2        2        1  \n",
       "122        1        1        2  \n",
       "123        2        2        2  \n",
       "124        2        3        1  \n",
       "125        1        0        4  \n",
       "\n",
       "[126 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_feat=training.data_creator(counts=True)\n",
    "eva_feat_out=eva_feat.fit(X=feat,y=tar).transform(X=feat)\n",
    "all_cat_feat=[feature for feature in eva_feat_out.columns if feature not in [\"F_w_mean\",\"mean\"]] \n",
    "eva_feat_out=eva_feat_out[all_cat_feat]\n",
    "eva_feat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61c0d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': [np.int64(1), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X2': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X3': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X4': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X5': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'X6': [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)],\n",
       " 'above_3': [np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'above_4': [np.float64(0.0),\n",
       "  np.float64(0.16666666666666666),\n",
       "  np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'above_5': [np.float64(0.0),\n",
       "  np.float64(0.16666666666666666),\n",
       "  np.float64(0.3333333333333333),\n",
       "  np.float64(0.5),\n",
       "  np.float64(0.6666666666666666),\n",
       "  np.float64(0.8333333333333334),\n",
       "  np.float64(1.0)],\n",
       " 'count_1': [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)],\n",
       " 'count_2': [np.int64(0), np.int64(1), np.int64(2), np.int64(3)],\n",
       " 'count_3': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)],\n",
       " 'count_4': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5)],\n",
       " 'count_5': [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5),\n",
       "  np.int64(6)]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cat=dict()\n",
    "for key in eva_feat_out.columns: \n",
    "    dict_cat[key]=sorted(list(eva_feat_out[key].unique()))\n",
    "dict_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7837366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X3', 'X5', 'X6', 'above_4', 'above_5', 'count_3', 'count_5'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel=training.data_selector()\n",
    "eva_sel_out=eva_sel.fit(X=eva_feat_out,y=tar).transform(X=eva_feat_out)\n",
    "eva_sel_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3fff798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>f score</th>\n",
       "      <th>p value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>above_3</th>\n",
       "      <th>above_4</th>\n",
       "      <th>above_5</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>10.561708</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.280160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>-0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>2.886959</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>0.516657</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>6.582716</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.224522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X6</td>\n",
       "      <td>3.586849</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>above_3</td>\n",
       "      <td>1.032794</td>\n",
       "      <td>0.311482</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.500598</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.491804</td>\n",
       "      <td>0.261704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>above_4</td>\n",
       "      <td>7.194813</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.492355</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.521454</td>\n",
       "      <td>0.616787</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>above_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_1</td>\n",
       "      <td>0.457080</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>-0.272144</td>\n",
       "      <td>-0.420657</td>\n",
       "      <td>-0.368676</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>-0.292405</td>\n",
       "      <td>-0.275081</td>\n",
       "      <td>-0.639627</td>\n",
       "      <td>-0.306616</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_2</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>-0.063015</td>\n",
       "      <td>-0.211012</td>\n",
       "      <td>-0.189451</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.330012</td>\n",
       "      <td>-0.054304</td>\n",
       "      <td>-0.625264</td>\n",
       "      <td>-0.282240</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.199957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.054321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_3</td>\n",
       "      <td>5.016985</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>-0.402565</td>\n",
       "      <td>-0.313167</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>-0.327806</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>-0.788134</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.103910</td>\n",
       "      <td>-0.121027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_4</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.858165</td>\n",
       "      <td>-0.182806</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.158830</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.280964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>-0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_5</td>\n",
       "      <td>6.520675</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.389949</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.490605</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.546995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-0.160484</td>\n",
       "      <td>-0.448806</td>\n",
       "      <td>-0.565327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features    f score   p value        X1        X2        X3        X4  \\\n",
       "0        X1  10.561708  0.001486  1.000000  0.059797  0.283358  0.087541   \n",
       "1        X2   0.073108  0.787313  0.059797  1.000000  0.184129  0.114838   \n",
       "2        X3   2.886959  0.091807  0.283358  0.184129  1.000000  0.302618   \n",
       "3        X4   0.516657  0.473623  0.087541  0.114838  0.302618  1.000000   \n",
       "4        X5   6.582716  0.011488  0.432772  0.039996  0.358397  0.293115   \n",
       "5        X6   3.586849  0.060568  0.411873 -0.062205  0.203750  0.215888   \n",
       "6   above_3   1.032794  0.311482  0.266199  0.500598  0.442280  0.383442   \n",
       "7   above_4   7.194813  0.008308  0.492355  0.268810  0.638649  0.521454   \n",
       "8   above_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "9   count_1   0.457080  0.500251 -0.272144 -0.420657 -0.368676 -0.308409   \n",
       "10  count_2   0.366975  0.545765 -0.063015 -0.211012 -0.189451 -0.175639   \n",
       "11  count_3   5.016985  0.026881 -0.362352  0.049254 -0.402565 -0.313167   \n",
       "12  count_4   0.032071  0.858165 -0.182806  0.027148  0.097357  0.083189   \n",
       "13  count_5   6.520675  0.011874  0.604855  0.215269  0.481689  0.389949   \n",
       "\n",
       "          X5        X6   above_3   above_4   above_5   count_1   count_2  \\\n",
       "0   0.432772  0.411873  0.266199  0.492355  0.604855 -0.272144 -0.063015   \n",
       "1   0.039996 -0.062205  0.500598  0.268810  0.215269 -0.420657 -0.211012   \n",
       "2   0.358397  0.203750  0.442280  0.638649  0.481689 -0.368676 -0.189451   \n",
       "3   0.293115  0.215888  0.383442  0.521454  0.389949 -0.308409 -0.175639   \n",
       "4   1.000000  0.320195  0.491804  0.616787  0.586695 -0.292405 -0.330012   \n",
       "5   0.320195  1.000000  0.261704  0.458477  0.490605 -0.275081 -0.054304   \n",
       "6   0.491804  0.261704  1.000000  0.465645  0.229256 -0.639627 -0.625264   \n",
       "7   0.616787  0.458477  0.465645  1.000000  0.546995 -0.306616 -0.282240   \n",
       "8   0.586695  0.490605  0.229256  0.546995  1.000000 -0.129758 -0.160484   \n",
       "9  -0.292405 -0.275081 -0.639627 -0.306616 -0.129758  1.000000 -0.199957   \n",
       "10 -0.330012 -0.054304 -0.625264 -0.282240 -0.160484 -0.199957  1.000000   \n",
       "11 -0.343809 -0.327806  0.177713 -0.788134 -0.448806 -0.103910 -0.121027   \n",
       "12 -0.040143 -0.090021  0.205652  0.381294 -0.565327 -0.158830 -0.100881   \n",
       "13  0.586695  0.490605  0.229256  0.546995  1.000000 -0.129758 -0.160484   \n",
       "\n",
       "     count_3   count_4   count_5         Y  \n",
       "0  -0.362352 -0.182806  0.604855  0.280160  \n",
       "1   0.049254  0.027148  0.215269 -0.024274  \n",
       "2  -0.402565  0.097357  0.481689  0.150838  \n",
       "3  -0.313167  0.083189  0.389949  0.064415  \n",
       "4  -0.343809 -0.040143  0.586695  0.224522  \n",
       "5  -0.327806 -0.090021  0.490605  0.167669  \n",
       "6   0.177713  0.205652  0.229256  0.090886  \n",
       "7  -0.788134  0.381294  0.546995  0.234181  \n",
       "8  -0.448806 -0.565327  1.000000  0.223515  \n",
       "9  -0.103910 -0.158830 -0.129758 -0.060602  \n",
       "10 -0.121027 -0.100881 -0.160484 -0.054321  \n",
       "11  1.000000 -0.280964 -0.448806 -0.197196  \n",
       "12 -0.280964  1.000000 -0.565327 -0.016080  \n",
       "13 -0.448806 -0.565327  1.000000  0.223515  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_sel.total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c18ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 255 | elapsed:  4.2min remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 255 out of 255 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "count_feats=list(eva_sel_out.columns)\n",
    "range_feat_combin = training.all_combin(count_feats)\n",
    "model_choice={\n",
    "    \"Categorical\": None\n",
    "    }\n",
    "\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "\n",
    "def evaluate_combo(list_f_sel_tuple, model_name, splits, feat, tar):\n",
    "    \"\"\"\n",
    "    Evaluate one (feature_set, n_neighbors) across all CV folds.\n",
    "    \n",
    "    :param list_f_sel_tuple: A tuple indicating a combination.\n",
    "    :param model_name: A str name of the NB model used. \n",
    "    :param splits: A list of the pre generated splits. \n",
    "    :param feat: The feat df. \n",
    "    :param tar: The tar df. \n",
    "    :return: A dict with all the stats we want. \n",
    "    \"\"\"\n",
    "    list_f_sel = list(list_f_sel_tuple) \n",
    "    fold_acc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    for train_index, test_index in splits:\n",
    "        x_tr, x_te = feat.iloc[train_index], feat.iloc[test_index]\n",
    "        y_tr, y_te = tar.iloc[train_index], tar.iloc[test_index]\n",
    "\n",
    "        y_tr = np.ravel(y_tr.values)\n",
    "        y_te = np.ravel(y_te.values)\n",
    "        \n",
    "        cats=[dict_cat[key] for key in list_f_sel]\n",
    "        \n",
    "        K=max(len(c) for c in cats)\n",
    "        \n",
    "        min_cats=[max(len(c), K + 1) for c in cats]\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=list_f_sel)),\n",
    "            (\"OrEncoder\", OrdinalEncoder(categories=cats,handle_unknown=\"use_encoded_value\",unknown_value=K,dtype=int)), \n",
    "            (\"NB\", CategoricalNB(min_categories=min_cats)),\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X=x_tr, y=y_tr)\n",
    "        y_p = pipe.predict(X=x_te)\n",
    "\n",
    "        fold_acc.append(accuracy_score(y_true=y_te, y_pred=y_p))\n",
    "        fold_f1.append(f1_score(y_true=y_te, y_pred=y_p))\n",
    "\n",
    "    str_model = model_name\n",
    "    str_features = \",\".join(list_f_sel)\n",
    "    acc_mean = float(np.mean(fold_acc))\n",
    "    acc_std  = float(np.std(fold_acc))\n",
    "    f1_mean  = float(np.mean(fold_f1))\n",
    "    f1_std   = float(np.std(fold_f1))\n",
    "    above_73 = float((np.array(fold_acc) >= 0.73).sum() / (len(splits)))\n",
    "    norm_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std))\n",
    "    acc_mean_above_73 = float(1-norm.cdf(0.73, loc=acc_mean, scale=acc_std/np.sqrt(len(splits))))\n",
    "\n",
    "    msg = (\n",
    "        \"_\"*20 + \"\\n\"\n",
    "        + f\"Currently used features {str_features} and {model_name} NB.\\n\"\n",
    "        + f\"This combo has f1 mean {f1_mean} and f1 std {f1_std}, \\n\"\n",
    "        + f\"with acc mean {acc_mean} acc std {acc_std}, \"\n",
    "        + f\"and sureness of beating 73% {above_73}.\\n\"\n",
    "        + \"_\"*20\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        #Hyper-parameters\n",
    "        \"model\": str_model,\n",
    "        \"features\": str_features,\n",
    "        #Performance\n",
    "        \"acc_mean\": acc_mean,\n",
    "        \"acc_std\": acc_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "        \"above_73\": above_73,\n",
    "        \"norm_above_73\": norm_above_73,\n",
    "        \"acc_mean_above_73\": acc_mean_above_73,\n",
    "        #Log\n",
    "        \"log\": msg,\n",
    "    }\n",
    "\n",
    "jobs = list(itertools.product(range_feat_combin, list(model_choice.keys())))\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "    delayed(evaluate_combo)(feat_sel, model, splits, feat, tar)\n",
    "    for feat_sel, model in jobs\n",
    ")\n",
    "\n",
    "#Hyper-parameter\n",
    "list_feat      = [r[\"features\"] for r in results]\n",
    "list_model     = [r[\"model\"] for r in results]\n",
    "#Performance \n",
    "list_acc_mean  = [r[\"acc_mean\"] for r in results]\n",
    "list_acc_std   = [r[\"acc_std\"] for r in results]\n",
    "list_f1_mean   = [r[\"f1_mean\"] for r in results]\n",
    "list_f1_std    = [r[\"f1_std\"] for r in results]\n",
    "list_above_73  = [r[\"above_73\"] for r in results]\n",
    "list_norm_above_73 = [r[\"norm_above_73\"] for r in results] \n",
    "list_acc_mean_above_73 = [r[\"acc_mean_above_73\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9ac2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats = pd.DataFrame({\n",
    "    #Hyper-parameters\n",
    "    \"features\": list_feat,\n",
    "    \"model\": list_model,\n",
    "    #Performances\n",
    "    \"acc_mean\": list_acc_mean,\n",
    "    \"acc_std\": list_acc_std,\n",
    "    \"f1_mean\": list_f1_mean,\n",
    "    \"f1_std\": list_f1_std,\n",
    "    \"above_73\": list_above_73,\n",
    "    \"norm_above_73\": list_norm_above_73, \n",
    "    \"acc_mean_above_73\": list_acc_mean_above_73\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac1537f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>above_73</th>\n",
       "      <th>norm_above_73</th>\n",
       "      <th>acc_mean_above_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X1,X6,above_4</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.661431</td>\n",
       "      <td>0.092942</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>0.094698</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.230330</td>\n",
       "      <td>8.060219e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X1,X6,above_4,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.640415</td>\n",
       "      <td>0.089925</td>\n",
       "      <td>0.689160</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.638292</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.148064</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>X1,X6,above_4,above_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.665343</td>\n",
       "      <td>0.091472</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>X1,X6,above_4,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.665343</td>\n",
       "      <td>0.091472</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>X3,X5,above_4,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.076875</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>X3,X5,above_4,above_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.076875</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>X5,X6,above_5,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.084510</td>\n",
       "      <td>0.590776</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>X1,X3,X5,above_4,count_3,count_5</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.584846</td>\n",
       "      <td>0.070933</td>\n",
       "      <td>0.626930</td>\n",
       "      <td>0.074792</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>X1,X3,X5,above_4,above_5,count_3</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.584846</td>\n",
       "      <td>0.070933</td>\n",
       "      <td>0.626930</td>\n",
       "      <td>0.074792</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features        model  acc_mean   acc_std  \\\n",
       "47                      X1,X6,above_4  Categorical  0.661431  0.092942   \n",
       "118             X1,X6,above_4,count_3  Categorical  0.640415  0.089925   \n",
       "0                                  X1  Categorical  0.638292  0.087778   \n",
       "117             X1,X6,above_4,above_5  Categorical  0.634769  0.087533   \n",
       "119             X1,X6,above_4,count_5  Categorical  0.634769  0.087533   \n",
       "..                                ...          ...       ...       ...   \n",
       "133             X3,X5,above_4,count_5  Categorical  0.578908  0.076875   \n",
       "131             X3,X5,above_4,above_5  Categorical  0.578908  0.076875   \n",
       "215     X5,X6,above_5,count_3,count_5  Categorical  0.564246  0.084510   \n",
       "226  X1,X3,X5,above_4,count_3,count_5  Categorical  0.584846  0.070933   \n",
       "224  X1,X3,X5,above_4,above_5,count_3  Categorical  0.584846  0.070933   \n",
       "\n",
       "      f1_mean    f1_std  above_73  norm_above_73  acc_mean_above_73  \n",
       "47   0.704892  0.094698      0.24       0.230330       8.060219e-14  \n",
       "118  0.689160  0.085676      0.16       0.159574       0.000000e+00  \n",
       "0    0.661949  0.088259      0.15       0.148064       0.000000e+00  \n",
       "117  0.665343  0.091472      0.11       0.138311       0.000000e+00  \n",
       "119  0.665343  0.091472      0.11       0.138311       0.000000e+00  \n",
       "..        ...       ...       ...            ...                ...  \n",
       "133  0.628913  0.082410      0.00       0.024683       0.000000e+00  \n",
       "131  0.628913  0.082410      0.00       0.024683       0.000000e+00  \n",
       "215  0.590776  0.103022      0.00       0.024919       0.000000e+00  \n",
       "226  0.626930  0.074792      0.00       0.020361       0.000000e+00  \n",
       "224  0.626930  0.074792      0.00       0.020361       0.000000e+00  \n",
       "\n",
       "[255 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_Cats.sort_values(by=[\"above_73\"],ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce648612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_Cats.to_csv(\"../data/NB_Cats_results_exhaust_raw6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf13195",
   "metadata": {},
   "source": [
    "Now we are talking, investigating into 47 might be worth our time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e18c3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2476    , 0.20470769],\n",
       "       [0.13386154, 0.41383077]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fold_acc=[]\n",
    "list_fold_f1=[]\n",
    "imp_record=None\n",
    "cmatrix_record=None\n",
    "n_split = 5\n",
    "n_repeats = 20\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=n_split, random_state=420, n_repeats=n_repeats)\n",
    "splits = list(RSKF.split(X=feat, y=tar))\n",
    "for train_index, test_index in splits: \n",
    "    x_tr,x_te=feat.iloc[train_index], feat.iloc[test_index]\n",
    "    y_tr, y_te=tar.iloc[train_index], tar.iloc[test_index]\n",
    "        \n",
    "    y_tr=np.ravel(y_tr.values)\n",
    "    y_te=np.ravel((y_te.values))\n",
    "        \n",
    "    cats=[dict_cat[key] for key in [\"X1\",\"X6\",\"above_4\"]]\n",
    "        \n",
    "    K=max(len(c) for c in cats)\n",
    "        \n",
    "    min_cats=[max(len(c), K + 1) for c in cats]\n",
    "        \n",
    "    pipe = Pipeline([\n",
    "            (\"DataCreate\", training.data_creator(counts=True)),\n",
    "            (\"DataSelect\", training.data_selector(force=[\"X1\",\"X6\",\"above_4\"])),\n",
    "            (\"OrEncoder\", OrdinalEncoder(categories=cats,handle_unknown=\"use_encoded_value\",unknown_value=K,dtype=int)), \n",
    "            (\"NB\", CategoricalNB(min_categories=min_cats)),\n",
    "        ])\n",
    "    pipe.fit(X=x_tr,y=y_tr)\n",
    "    y_p=pipe.predict(X=x_te)\n",
    "    acc=accuracy_score(y_pred=y_p,y_true=y_te)\n",
    "    f1=f1_score(y_pred=y_p,y_true=y_te)\n",
    "    list_fold_acc.append(acc)\n",
    "    list_fold_f1.append(f1)\n",
    "    # with parallel_backend(\"threading\", n_jobs=-1):\n",
    "    #     with threadpool_limits(limits=1):\n",
    "    imp=permutation_importance(pipe,X=x_te.copy(deep=True),y=y_te,scoring=\"accuracy\",n_repeats=30,n_jobs=-1,random_state=420)\n",
    "    if imp_record is None: \n",
    "        imp_record=imp.importances_mean\n",
    "    else: \n",
    "        imp_record=imp_record+imp.importances_mean\n",
    "    cmatrix=confusion_matrix(y_pred=y_p,y_true=y_te)\n",
    "    cmatrix=cmatrix/np.sum(cmatrix)\n",
    "    if cmatrix_record is None: \n",
    "        cmatrix_record=cmatrix\n",
    "    else: \n",
    "        cmatrix_record=cmatrix_record+cmatrix\n",
    "    \n",
    "\n",
    "plt.hist(list_fold_acc,bins=25)\n",
    "plt.show()\n",
    "\n",
    "imp_record=imp_record/len(splits)\n",
    "imp_sort_index=imp_record.argsort()\n",
    "plt.barh(feat.columns[imp_sort_index], imp_record[imp_sort_index])\n",
    "plt.title(\"Feature importance by permutaion method\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "cmatrix_record=cmatrix_record/len(splits)\n",
    "cmatrix_record #This is the \"Average confusion matrix\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b475e",
   "metadata": {},
   "source": [
    "It is interesting how X6 is present in the selected features, yet have the least importance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
